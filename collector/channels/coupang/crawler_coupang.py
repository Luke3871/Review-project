#//==============================================================================//#
"""
ì¿ íŒ¡ í†µí•© í¬ë¡¤ëŸ¬ (ì œí’ˆ ìˆ˜ì§‘ + ë¦¬ë·° ìˆ˜ì§‘)
- ì œí’ˆ ëª©ë¡ ìë™ ìˆ˜ì§‘
- ìˆ˜ì§‘ëœ ì œí’ˆì˜ ëª¨ë“  ë¦¬ë·° í¬ë¡¤ë§
- ì œí’ˆë³„ ì¦‰ì‹œ ì €ì¥ (ë‹¤ì´ì†Œ ë°©ì‹)

last_updated : 2025.09.29
"""
#//==============================================================================//#

import time
import pandas as pd
import os
from datetime import datetime
from selenium.webdriver.common.by import By
from random import randint
from driver_coupang import make_driver
from navigator_coupang import navigate_to_category, collect_product_cards, go_to_page
from parser_coupang import parse_product_card
from config_coupang import (
    PRODUCT_NAME_DETAIL,
    PRODUCT_PRICE_SALE_DETAIL,
    PRODUCT_PRICE_ORIGINAL_DETAIL,
    PRODUCT_DISCOUNT_RATE_DETAIL,
)

#//==============================================================================//#
# STEP 1: ì œí’ˆ ëª©ë¡ ìˆ˜ì§‘
#//==============================================================================//#
def collect_products(category, sort_type, max_products=100):
    """íŠ¹ì • ì¹´í…Œê³ ë¦¬/ì •ë ¬ ì¡°ê±´ì˜ ì œí’ˆ ëª©ë¡ ìˆ˜ì§‘"""
    print(f"\n{'='*60}")
    print(f"ì œí’ˆ ìˆ˜ì§‘ | ì¹´í…Œê³ ë¦¬: {category} | ì •ë ¬: {sort_type}")
    print(f"{'='*60}")
    
    driver = make_driver()
    products = []
    
    try:
        # ì¹´í…Œê³ ë¦¬ í˜ì´ì§€ ì´ë™
        if not navigate_to_category(driver, category, sort_type, list_size=120):
            print("í˜ì´ì§€ ì´ë™ ì‹¤íŒ¨")
            return products
        
        # ì œí’ˆ ì¹´ë“œ ìˆ˜ì§‘
        product_cards = collect_product_cards(driver, max_products=max_products)
        
        if not product_cards:
            print("ì œí’ˆ ì¹´ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return products
        
        # ê° ì œí’ˆ ì¹´ë“œ íŒŒì‹±
        for rank, card in enumerate(product_cards, 1):
            product_data = parse_product_card(card, rank, category, sort_type)
            
            if product_data:
                products.append(product_data)
                print(f"[{rank}] {product_data['name'][:40]}...")
            
            time.sleep(randint(1, 2))
        
        print(f"\nìˆ˜ì§‘ ì™„ë£Œ: {len(products)}ê°œ ì œí’ˆ")
        
    except Exception as e:
        print(f"ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}")
    
    finally:
        driver.quit()
    
    return products

def collect_all_products():
    """ëª¨ë“  ì¹´í…Œê³ ë¦¬/ì •ë ¬ ì¡°í•©ì˜ ì œí’ˆ ëª©ë¡ ìˆ˜ì§‘"""
    print("\n" + "#"*60)
    print("STEP 1: ì œí’ˆ ëª©ë¡ ìˆ˜ì§‘")
    print("#"*60)
    
    categories = ['skincare', 'makeup']
    sort_types = ['SALES', 'RANKED_COUPANG']
    
    save_dir = os.path.join("data", "data_coupang", "raw_data", "products_coupang")
    os.makedirs(save_dir, exist_ok=True)
    
    all_products = []
    
    for category in categories:
        for sort_type in sort_types:
            products = collect_products(category, sort_type, max_products=100)
            
            if products:
                # DataFrame ë³€í™˜ ë° ì €ì¥
                df = pd.DataFrame(products)
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"coupang_{category}_{sort_type}_{timestamp}.csv"
                filepath = os.path.join(save_dir, filename)
                
                df.to_csv(filepath, index=False, encoding='utf-8-sig')
                print(f"ğŸ’¾ ì €ì¥: {filename} ({len(products)}ê°œ)")
                
                all_products.extend(products)
            
            # ë‹¤ìŒ ì¡°í•© ì „ ëŒ€ê¸°
            time.sleep(5)
    
    print(f"\nì œí’ˆ ìˆ˜ì§‘ ì™„ë£Œ: ì´ {len(all_products)}ê°œ")
    return all_products

#//==============================================================================//#
# STEP 2: ë¦¬ë·° ìˆ˜ì§‘
#//==============================================================================//#
def extract_product_info(driver):
    """ì œí’ˆ ìƒì„¸ í˜ì´ì§€ì—ì„œ ì œí’ˆ ì •ë³´ ì¶”ì¶œ"""
    product_info = {}
    
    try:
        # ì œí’ˆëª…
        try:
            product_name_elem = driver.find_element(By.CSS_SELECTOR, PRODUCT_NAME_DETAIL)
            product_info['product_name'] = product_name_elem.text.strip()
        except:
            product_info['product_name'] = driver.title
        
        # í• ì¸ëœ ê°€ê²©
        try:
            sale_price_elem = driver.find_element(By.CSS_SELECTOR, PRODUCT_PRICE_SALE_DETAIL)
            product_info['sale_price'] = sale_price_elem.text.strip()
        except:
            product_info['sale_price'] = None
        
        # ì›ë˜ ê°€ê²©
        try:
            original_price_elem = driver.find_element(By.CSS_SELECTOR, PRODUCT_PRICE_ORIGINAL_DETAIL)
            product_info['original_price'] = original_price_elem.text.strip()
        except:
            product_info['original_price'] = None
        
        # í• ì¸ìœ¨
        try:
            discount_elem = driver.find_element(By.CSS_SELECTOR, PRODUCT_DISCOUNT_RATE_DETAIL)
            product_info['discount_rate'] = discount_elem.text.strip()
        except:
            product_info['discount_rate'] = None
        
        return product_info
        
    except Exception as e:
        print(f"ì œí’ˆ ì •ë³´ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        return None

def collect_product_reviews(driver, product_info, max_pages=None):
    """ê°œë³„ ì œí’ˆì˜ ë¦¬ë·° ìˆ˜ì§‘ (í˜ì´ì§€ë„¤ì´ì…˜ í¬í•¨)"""
    from bs4 import BeautifulSoup
    
    all_reviews = []
    page = 1
    
    # ì œí’ˆ ìƒì„¸ ì •ë³´ ì¶”ì¶œ
    detailed_info = extract_product_info(driver)
    if detailed_info:
        product_info.update(detailed_info)
    
    while True:
        try:
            print(f"  í˜ì´ì§€ {page} ì²˜ë¦¬ ì¤‘...", end=" ")
            
            # BeautifulSoup íŒŒì‹±
            doc = BeautifulSoup(driver.page_source, "html.parser")
            
            # ë¦¬ë·° ìš”ì†Œ ìˆ˜ì§‘
            reviewer_names = [n.text.strip() if n and n.text.strip() else "ìµëª…" 
                            for n in doc.find_all("span", class_="sdp-review__article__list__info__user__name")]
            
            review_stars = []
            for elem in doc.find_all(attrs={"data-rating": True}):
                rating = elem.get("data-rating")
                review_stars.append(rating if rating else "0")
            
            review_dates = [d.text.strip() if d and d.text.strip() else "ë‚ ì§œ ì—†ìŒ" 
                          for d in doc.find_all(class_='sdp-review__article__list__info__product-info__reg-date')]
            
            review_contents = [r.text.strip() if r and r.text.strip() else None 
                             for r in doc.find_all(class_='sdp-review__article__list__review__content')]
            
            # ë¦¬ë·° ë°ì´í„° êµ¬ì„±
            min_length = min(len(reviewer_names), len(review_stars), 
                           len(review_dates), len(review_contents))
            
            page_reviews = 0
            for i in range(min_length):
                if not review_contents[i]:
                    continue
                    
                review_data = {
                    'product_url': product_info['url'],
                    'product_name': product_info.get('product_name', product_info['name']),
                    'sale_price': product_info.get('sale_price', None),
                    'original_price': product_info.get('original_price', None),
                    'discount_rate': product_info.get('discount_rate', None),
                    'category': product_info['category'],
                    'sort_type': product_info['sort_type'],
                    'rank': product_info['rank'],
                    'reviewer_name': reviewer_names[i] if i < len(reviewer_names) else "ìµëª…",
                    'rating': review_stars[i] if i < len(review_stars) else "0",
                    'review_date': review_dates[i] if i < len(review_dates) else "ë‚ ì§œ ì—†ìŒ",
                    'review_text': review_contents[i],
                }
                all_reviews.append(review_data)
                page_reviews += 1
            
            print(f"{page_reviews}ê°œ ë¦¬ë·°")
            
            # ìµœëŒ€ í˜ì´ì§€ ì œí•œ
            if max_pages and page >= max_pages:
                break
            
            # ë‹¤ìŒ í˜ì´ì§€ ì´ë™
            next_page = page + 1
            if not go_to_page(driver, next_page):
                break
            
            page += 1
            time.sleep(randint(1, 2))
                
        except Exception as e:
            print(f"ì˜¤ë¥˜: {e}")
            break
    
    # ì œí’ˆë³„ ì¦‰ì‹œ ì €ì¥
    if all_reviews:
        reviews_dir = os.path.join("data", "data_coupang", "raw_data", "reviews_coupang")
        os.makedirs(reviews_dir, exist_ok=True)
        
        safe_name = product_info['name'].replace('/', '_').replace('\\', '_')[:50]
        filename = f"{product_info['category']}_{product_info['sort_type']}_rank{product_info['rank']:03d}_{safe_name}.csv"
        filepath = os.path.join(reviews_dir, filename)
        
        reviews_df = pd.DataFrame(all_reviews)
        reviews_df.to_csv(filepath, index=False, encoding='utf-8-sig')
        print(f" ì €ì¥: {len(all_reviews)}ê°œ ë¦¬ë·°")
    
    return all_reviews

def crawl_all_reviews(products, max_pages_per_product=None):
    """ëª¨ë“  ì œí’ˆì˜ ë¦¬ë·° ìˆ˜ì§‘"""
    print("\n" + "#"*60)
    print("STEP 2: ë¦¬ë·° ìˆ˜ì§‘")
    print("#"*60)
    print(f"ì´ ì œí’ˆ ìˆ˜: {len(products)}ê°œ\n")
    
    driver = make_driver()
    
    try:
        for i, product in enumerate(products, 1):
            print(f"\n[{i}/{len(products)}] {product['name'][:50]}...")
            
            try:
                driver.get(product['url'])
                time.sleep(1)
                
                reviews = collect_product_reviews(driver, product, max_pages_per_product)
                print(f" ì™„ë£Œ: {len(reviews)}ê°œ ë¦¬ë·°")
                
                time.sleep(randint(1, 2))
                
            except Exception as e:
                print(f" {e}")
                continue
        
        print(f"ë¦¬ë·° ìˆ˜ì§‘ ì™„ë£Œ!")
        
    except Exception as e:
        print(f"ë¦¬ë·° ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}")
    
    finally:
        driver.quit()

#//==============================================================================//#
# ë©”ì¸ ì‹¤í–‰
#//==============================================================================//#
def main():
    """í†µí•© ì‹¤í–‰: ì œí’ˆ ìˆ˜ì§‘ â†’ ë¦¬ë·° ìˆ˜ì§‘"""
    print("\n" + "="*60)
    print("ì¿ íŒ¡ í†µí•© í¬ë¡¤ëŸ¬ ì‹œì‘")
    print("="*60)
    
    try:
        # STEP 1: ì œí’ˆ ëª©ë¡ ìˆ˜ì§‘
        products = collect_all_products()
        
        if not products:
            print("ì œí’ˆ ìˆ˜ì§‘ ì‹¤íŒ¨")
            return
        
        # STEP 2: ë¦¬ë·° ìˆ˜ì§‘
        crawl_all_reviews(products, max_pages_per_product=None)
        
        print("\n" + "="*60)
        print("ëª¨ë“  ì‘ì—… ì™„ë£Œ!")
        print("="*60)
        
    except KeyboardInterrupt:
        print("\n\nì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨")
    except Exception as e:
        print(f"\n{e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()