#//==============================================================================//#
"""
ì¿ íŒ¡ ë¦¬ë·° ìˆ˜ì§‘ - ë””ë²„ê¹… & ê°œì„  ë²„ì „
- ìƒì„¸í•œ ë¡œê¹… ì¶”ê°€
- ì—ëŸ¬ í•¸ë“¤ë§ ê°•í™”
- êµ¬ì¡° í™•ì¸ ê¸°ëŠ¥ ì¶”ê°€

last_updated : 2025.09.30
"""
#//==============================================================================//#

import time
import pandas as pd
import os
import glob
from datetime import datetime
from random import randint
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from driver_coupang import make_driver
from navigator_coupang import go_to_page

#//==============================================================================//#
# ë””ë²„ê¹…: í˜ì´ì§€ êµ¬ì¡° í™•ì¸
#//==============================================================================//#
def debug_page_structure(driver, product_name):
    """í˜„ì¬ í˜ì´ì§€ì˜ ë¦¬ë·° êµ¬ì¡°ë¥¼ ë¶„ì„"""
    from bs4 import BeautifulSoup
    
    print(f"\n{'='*60}")
    print(f"ğŸ” í˜ì´ì§€ êµ¬ì¡° ë””ë²„ê¹…: {product_name[:50]}")
    print(f"{'='*60}")
    
    doc = BeautifulSoup(driver.page_source, "html.parser")
    
    # 1. ë¦¬ë·° ì»¨í…Œì´ë„ˆ í™•ì¸
    review_containers = doc.find_all("article", class_="sdp-review__article__list")
    print(f"âœ“ ë¦¬ë·° ì»¨í…Œì´ë„ˆ ('article.sdp-review__article__list'): {len(review_containers)}ê°œ")
    
    if not review_containers:
        print("\nâš ï¸ ë¦¬ë·° ì»¨í…Œì´ë„ˆë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
        print("\në‹¤ë¥¸ ê°€ëŠ¥í•œ ì„ íƒìë“¤ì„ í™•ì¸ ì¤‘...")
        
        # ëŒ€ì•ˆ ì„ íƒì í™•ì¸
        alternatives = [
            ("div.sdp-review__article__list", doc.find_all("div", class_="sdp-review__article__list")),
            ("article[class*='review']", doc.find_all("article", class_=lambda x: x and 'review' in x)),
            ("div[class*='review'][class*='list']", doc.find_all("div", class_=lambda x: x and 'review' in x and 'list' in x)),
        ]
        
        for selector, elements in alternatives:
            if elements:
                print(f"  âœ“ ë°œê²¬: {selector} â†’ {len(elements)}ê°œ")
        
        # HTML ì¼ë¶€ ì €ì¥
        debug_dir = "debug_html"
        os.makedirs(debug_dir, exist_ok=True)
        debug_file = os.path.join(debug_dir, f"debug_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html")
        with open(debug_file, 'w', encoding='utf-8') as f:
            f.write(driver.page_source)
        print(f"\nğŸ’¾ ì „ì²´ HTML ì €ì¥: {debug_file}")
        
        return False
    
    # 2. ì²« ë²ˆì§¸ ë¦¬ë·°ì˜ êµ¬ì¡° ë¶„ì„
    print("\nğŸ“‹ ì²« ë²ˆì§¸ ë¦¬ë·° êµ¬ì¡° ë¶„ì„:")
    first_review = review_containers[0]
    
    # ë¦¬ë·°ì–´ ì´ë¦„
    reviewer_elem = first_review.find("span", class_="sdp-review__article__list__info__user__name")
    print(f"  â€¢ ë¦¬ë·°ì–´ ì´ë¦„: {'âœ“' if reviewer_elem else 'âœ—'} {reviewer_elem.text.strip() if reviewer_elem else 'N/A'}")
    
    # í‰ì 
    rating_elem = first_review.find(attrs={"data-rating": True})
    print(f"  â€¢ í‰ì : {'âœ“' if rating_elem else 'âœ—'} {rating_elem.get('data-rating') if rating_elem else 'N/A'}")
    
    # ë‚ ì§œ
    date_elem = first_review.find(class_='sdp-review__article__list__info__product-info__reg-date')
    print(f"  â€¢ ë¦¬ë·° ë‚ ì§œ: {'âœ“' if date_elem else 'âœ—'} {date_elem.text.strip() if date_elem else 'N/A'}")
    
    # ë¦¬ë·° ë‚´ìš©
    content_elem = first_review.find(class_='sdp-review__article__list__review__content')
    print(f"  â€¢ ë¦¬ë·° ë‚´ìš©: {'âœ“' if content_elem else 'âœ—'} {content_elem.text.strip()[:50] if content_elem else 'N/A'}...")
    
    # ë„ì›€ì´ ë¨
    help_elem = first_review.find(class_='sdp-review__article__list__help')
    print(f"  â€¢ ë„ì›€ì´ ë¨: {'âœ“' if help_elem else 'âœ—'} {help_elem.get('data-count') if help_elem else 'N/A'}")
    
    # êµ¬ë§¤ ì˜µì…˜
    option_elem = first_review.find("div", class_="sdp-review__article__list__info__product-info__name")
    print(f"  â€¢ êµ¬ë§¤ ì˜µì…˜: {'âœ“' if option_elem else 'âœ—'} {option_elem.text.strip() if option_elem else 'N/A'}")
    
    print(f"\n{'='*60}\n")
    return True

#//==============================================================================//#
# ë¦¬ë·° ìˆ˜ì§‘ í•¨ìˆ˜ (ê°œì„  ë²„ì „)
#//==============================================================================//#
def collect_product_reviews(driver, product_info, max_pages_per_product, collection_date, debug_mode=False):
    """ê°œë³„ ì œí’ˆì˜ ë¦¬ë·° ìˆ˜ì§‘ (í˜ì´ì§€ë„¤ì´ì…˜ í¬í•¨)"""
    from bs4 import BeautifulSoup
    
    all_reviews = []
    page = 1
    
    # ë””ë²„ê·¸ ëª¨ë“œ: ì²« í˜ì´ì§€ êµ¬ì¡° í™•ì¸
    if debug_mode and page == 1:
        if not debug_page_structure(driver, product_info['name']):
            return []  # êµ¬ì¡° íŒŒì•… ì‹¤íŒ¨ ì‹œ ì¤‘ë‹¨
    
    # ì œí’ˆ ìƒì„¸ í˜ì´ì§€ì—ì„œ ì¶”ê°€ ì •ë³´ ì¶”ì¶œ (ìµœì´ˆ 1íšŒë§Œ)
    brand_name = ""
    category_use = ""
    
    try:
        doc_initial = BeautifulSoup(driver.page_source, "html.parser")
        
        # ë¸Œëœë“œëª… ì¶”ì¶œ
        brand_elem = doc_initial.find("div", class_="twc-text-sm twc-text-blue-600")
        if brand_elem:
            brand_name = brand_elem.text.strip()
        
        # ì„¸ë¶€ ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ (breadcrumb ë§ˆì§€ë§‰ ë‘ í•­ëª©)
        breadcrumb_items = doc_initial.select("ul.breadcrumb li a")
        if breadcrumb_items:
            if len(breadcrumb_items) >= 2:
                category_use = f"{breadcrumb_items[-2].text.strip()} > {breadcrumb_items[-1].text.strip()}"
            else:
                category_use = breadcrumb_items[-1].text.strip()
            print(f"    [ë¸Œëœë“œ: {brand_name}] [ì„¸ë¶€ì¹´í…Œê³ ë¦¬: {category_use}]")
    except Exception as e:
        print(f"    [ì œí’ˆì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨: {e}]")
    
    # í˜ì´ì§€ë„¤ì´ì…˜ ë£¨í”„
    consecutive_empty_pages = 0  # ì—°ì† ë¹ˆ í˜ì´ì§€ ì¹´ìš´í„°
    
    while True:
        try:
            print(f"  í˜ì´ì§€ {page} ì²˜ë¦¬ ì¤‘...", end=" ")
            
            # BeautifulSoup íŒŒì‹±
            doc = BeautifulSoup(driver.page_source, "html.parser")
            
            # ë¦¬ë·° ì»¨í…Œì´ë„ˆ ì°¾ê¸°
            review_containers = doc.find_all("article", class_="sdp-review__article__list")
            
            if not review_containers:
                print("ë¦¬ë·° ì—†ìŒ", end=" ")
                consecutive_empty_pages += 1
                
                # ì—°ì† 3í˜ì´ì§€ ë¦¬ë·° ì—†ìœ¼ë©´ ì¢…ë£Œ
                if consecutive_empty_pages >= 3:
                    print("\n  âš ï¸ ì—°ì† 3í˜ì´ì§€ ë¦¬ë·° ì—†ìŒ. ìˆ˜ì§‘ ì¢…ë£Œ")
                    break
                
                # ë‹¤ìŒ í˜ì´ì§€ ì‹œë„
                page += 1
                if not go_to_page(driver, page):
                    break
                time.sleep(randint(1, 2))
                continue
            
            # ë¦¬ë·° ìˆìœ¼ë©´ ì¹´ìš´í„° ë¦¬ì…‹
            consecutive_empty_pages = 0
            
            # ëª¨ë“  help_countë¥¼ data-count ì†ì„±ì—ì„œ ìˆ˜ì§‘
            all_help_counts = []
            try:
                help_containers = driver.find_elements(By.CSS_SELECTOR, ".sdp-review__article__list__help")
                all_help_counts = [elem.get_attribute("data-count") or "0" for elem in help_containers]
                print(f"(help_count {len(all_help_counts)}ê°œ)", end=" ")
            except Exception as e:
                print(f"(help_countì˜¤ë¥˜:{e})", end=" ")
            
            # í‰ê°€ í•­ëª© ìˆ˜ì§‘ (í–¥ ë§Œì¡±ë„, ë°œìƒ‰ ë“±) - ìˆìœ¼ë©´
            all_survey_data = []
            try:
                survey_containers = doc.find_all("div", class_="sdp-review__article__list__survey")
                
                if debug_mode and page == 1:
                    print(f"\n  ğŸ” Survey ì»¨í…Œì´ë„ˆ ë°œê²¬: {len(survey_containers)}ê°œ")
                
                for survey_elem in survey_containers:
                    survey_dict = {}
                    items = survey_elem.find_all("div", class_="sdp-review__article__list__survey__row")
                    
                    for item in items:
                        label_elem = item.find("span", class_="sdp-review__article__list__survey__row__label")
                        value_elem = item.find("span", class_="sdp-review__article__list__survey__row__value")
                        if label_elem and value_elem:
                            label = label_elem.text.strip()
                            value = value_elem.text.strip()
                            survey_dict[label] = value
                            
                            if debug_mode and page == 1 and len(all_survey_data) == 0:
                                print(f"    â€¢ {label}: {value}")
                    
                    all_survey_data.append(survey_dict)
                
                if debug_mode and page == 1:
                    print(f"  ğŸ“Š ì´ survey_data ìˆ˜ì§‘: {len(all_survey_data)}ê°œ")
                    if len(all_survey_data) == 0:
                        print(f"  âš ï¸ Survey ë°ì´í„° ì—†ìŒ - ì´ ì œí’ˆì—ëŠ” í‰ê°€ í•­ëª©ì´ ì—†ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤")
                    
            except Exception as e:
                if debug_mode:
                    print(f"  âŒ Survey ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
            
            page_reviews = 0
            for idx, container in enumerate(review_containers):
                try:
                    # ë¦¬ë·°ì–´ ì´ë¦„
                    reviewer_name_elem = container.find("span", class_="sdp-review__article__list__info__user__name")
                    reviewer_name = reviewer_name_elem.text.strip() if reviewer_name_elem else "ìµëª…"
                    
                    # í‰ì 
                    rating_elem = container.find(attrs={"data-rating": True})
                    rating = rating_elem.get("data-rating") if rating_elem else "0"
                    
                    # ë¦¬ë·° ë‚ ì§œ
                    date_elem = container.find(class_='sdp-review__article__list__info__product-info__reg-date')
                    review_date = date_elem.text.strip() if date_elem else ""
                    
                    # ë¦¬ë·° ë‚´ìš©
                    content_elem = container.find(class_='sdp-review__article__list__review__content')
                    review_text = content_elem.text.strip() if content_elem else None
                    
                    if not review_text:
                        continue
                    
                    # ë„ì›€ì´ ë¨ ì¹´ìš´íŠ¸ (ìˆœì„œ ë§¤ì¹­)
                    helpful_count = all_help_counts[idx] if idx < len(all_help_counts) else "0"
                    
                    # ì„ íƒ ì˜µì…˜ (êµ¬ë§¤ ì˜µì…˜)
                    selected_option = ""
                    try:
                        option_elem = container.find("div", class_="sdp-review__article__list__info__product-info__name")
                        if option_elem:
                            selected_option = option_elem.text.strip()
                    except:
                        pass
                    
                    # í‰ê°€ í•­ëª© (í–¥ ë§Œì¡±ë„, ë°œìƒ‰ ë“±) - ìˆœì„œ ë§¤ì¹­
                    survey_data = all_survey_data[idx] if idx < len(all_survey_data) else {}
                    
                    if debug_mode and page == 1 and idx == 0:
                        print(f"\n  ğŸ“‹ ì²« ë²ˆì§¸ ë¦¬ë·°ì˜ survey_data: {survey_data}")
                    
                    # review_id ìƒì„±
                    review_id = f"coupang_{product_info['rank']:03d}_{page:03d}_{idx+1:03d}"
                    
                    # ë¦¬ë·° ë°ì´í„° êµ¬ì„± (í‘œì¤€ ì»¬ëŸ¼ëª… ì‚¬ìš© + survey_data í¬í•¨)
                    review_data = {
                        'review_id': review_id,
                        'captured_at': collection_date,
                        'channel': 'Coupang',
                        'product_url': product_info['url'],
                        'product_name': product_info['name'],
                        'brand': brand_name,
                        'category': product_info['category'],
                        'category_use': category_use,
                        'product_price_sale': product_info.get('sale_price', ''),
                        'product_price_origin': product_info.get('original_price', ''),
                        'sort_type': product_info['sort_type'],
                        'ranking': product_info['rank'],
                        'reviewer_name': reviewer_name,
                        'rating': rating,
                        'review_date': review_date,
                        'selected_option': selected_option,
                        'helpful_count': helpful_count,
                        'review_text': review_text
                    }
                    
                    # survey_data ì¶”ê°€ (í–¥ ë§Œì¡±ë„, ë°œìƒ‰ ë“±)
                    review_data.update(survey_data)
                    
                    if debug_mode and page == 1 and idx == 0:
                        print(f"  ğŸ’¾ ì²« ë²ˆì§¸ ë¦¬ë·° ì „ì²´ ë°ì´í„° í‚¤: {list(review_data.keys())}")
                    
                    all_reviews.append(review_data)
                    page_reviews += 1
                    
                except Exception as e:
                    if debug_mode:
                        print(f"\n  âš ï¸ ë¦¬ë·° íŒŒì‹± ì˜¤ë¥˜ (idx={idx}): {e}")
                    continue
            
            print(f"âœ“ {page_reviews}ê°œ ë¦¬ë·°")
            
            # ìµœëŒ€ í˜ì´ì§€ ì œí•œ
            if max_pages_per_product and page >= max_pages_per_product:
                print(f"  âš ï¸ ìµœëŒ€ í˜ì´ì§€({max_pages_per_product}) ë„ë‹¬")
                break
            
            # ë‹¤ìŒ í˜ì´ì§€ ì´ë™
            next_page = page + 1
            if not go_to_page(driver, next_page):
                print(f"  âš ï¸ í˜ì´ì§€ ì´ë™ ì‹¤íŒ¨ (page={next_page})")
                break
            
            page += 1
            time.sleep(randint(1, 2))
                
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜: {e}")
            if debug_mode:
                import traceback
                traceback.print_exc()
            break
    
    # ì œí’ˆë³„ ì¦‰ì‹œ ì €ì¥
    if all_reviews:
        reviews_dir = os.path.join("data", "data_coupang", "raw_data", "reviews_coupang")
        os.makedirs(reviews_dir, exist_ok=True)
        
        safe_name = product_info['name'].replace('/', '_').replace('\\', '_')[:50]
        filename = f"{product_info['category']}_{product_info['sort_type']}_rank{product_info['rank']:03d}_{safe_name}.csv"
        filepath = os.path.join(reviews_dir, filename)
        
        reviews_df = pd.DataFrame(all_reviews)
        
        if debug_mode:
            print(f"\n  ğŸ“Š DataFrame ì»¬ëŸ¼: {list(reviews_df.columns)}")
            print(f"  ğŸ“Š Survey ê´€ë ¨ ì»¬ëŸ¼: {[col for col in reviews_df.columns if col not in ['review_id', 'captured_at', 'channel', 'product_url', 'product_name', 'brand', 'category', 'category_use', 'product_price_sale', 'product_price_origin', 'sort_type', 'ranking', 'reviewer_name', 'rating', 'review_date', 'selected_option', 'helpful_count', 'review_text']]}")
        
        reviews_df.to_csv(filepath, index=False, encoding='utf-8-sig')
        print(f"  ğŸ’¾ ì €ì¥: {len(all_reviews)}ê°œ ë¦¬ë·° â†’ {filename}")
    else:
        print(f"  âš ï¸ ìˆ˜ì§‘ëœ ë¦¬ë·° ì—†ìŒ")
    
    return all_reviews

#//==============================================================================//#
# CSVì—ì„œ ì œí’ˆ ì •ë³´ ë¡œë“œ
#//==============================================================================//#
def load_products_from_csv():
    """ê¸°ì¡´ ì œí’ˆ CSV íŒŒì¼ë“¤ì„ ì½ì–´ì„œ ì œí’ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜"""
    products_dir = os.path.join("data", "data_coupang", "raw_data", "products_coupang")
    
    if not os.path.exists(products_dir):
        print(f"âŒ ì œí’ˆ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {products_dir}")
        return []
    
    csv_files = glob.glob(os.path.join(products_dir, "coupang_*.csv"))
    
    if not csv_files:
        print(f"âŒ CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {products_dir}")
        return []
    
    print(f"\nâœ“ ë°œê²¬ëœ CSV íŒŒì¼: {len(csv_files)}ê°œ")
    for csv_file in csv_files:
        print(f"  - {os.path.basename(csv_file)}")
    
    # ëª¨ë“  CSV íŒŒì¼ ì½ê¸°
    all_products = []
    for csv_file in csv_files:
        try:
            df = pd.read_csv(csv_file, encoding='utf-8-sig')
            products = df.to_dict('records')
            all_products.extend(products)
            print(f"  âœ“ {os.path.basename(csv_file)}: {len(products)}ê°œ ì œí’ˆ")
        except Exception as e:
            print(f"  âŒ {os.path.basename(csv_file)}: ì½ê¸° ì‹¤íŒ¨ - {e}")
    
    print(f"\nâœ“ ì´ ì œí’ˆ ìˆ˜: {len(all_products)}ê°œ")
    return all_products

#//==============================================================================//#
# ë¦¬ë·° ìˆ˜ì§‘ ë©”ì¸ í•¨ìˆ˜
#//==============================================================================//#
def crawl_reviews_only(max_pages_per_product=None, start_from=0, debug_mode=False):
    """
    ê¸°ì¡´ ì œí’ˆ CSVì—ì„œ ì½ì–´ì˜¨ ì œí’ˆë“¤ì˜ ë¦¬ë·°ë§Œ ìˆ˜ì§‘
    
    Args:
        max_pages_per_product: ì œí’ˆë‹¹ ìµœëŒ€ í˜ì´ì§€ ìˆ˜ (None = ë¬´ì œí•œ)
        start_from: ëª‡ ë²ˆì§¸ ì œí’ˆë¶€í„° ì‹œì‘í• ì§€ (0ë¶€í„° ì‹œì‘)
        debug_mode: ë””ë²„ê·¸ ëª¨ë“œ í™œì„±í™” (True/False)
    """
    print("\n" + "="*60)
    print("ğŸ›’ ì¿ íŒ¡ ë¦¬ë·° ìˆ˜ì§‘ ì‹œì‘ (ì œí’ˆ CSV ì½ê¸°)")
    print("="*60)
    
    # ìˆ˜ì§‘ ì‹œì‘ ì‹œê°„ ê¸°ë¡
    collection_date = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    print(f"â° ìˆ˜ì§‘ ì‹œì‘ ì‹œê°„: {collection_date}")
    print(f"ğŸ”§ ë””ë²„ê·¸ ëª¨ë“œ: {'ON' if debug_mode else 'OFF'}")
    
    # CSVì—ì„œ ì œí’ˆ ì •ë³´ ë¡œë“œ
    products = load_products_from_csv()
    
    if not products:
        print("âŒ ì œí’ˆ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # start_from ì ìš©
    if start_from > 0:
        products = products[start_from:]
        print(f"\nâ–¶ï¸ {start_from+1}ë²ˆì§¸ ì œí’ˆë¶€í„° ì‹œì‘ (ë‚¨ì€ ì œí’ˆ: {len(products)}ê°œ)")
    
    driver = make_driver()
    
    try:
        success_count = 0
        fail_count = 0
        total_reviews = 0
        
        for i, product in enumerate(products, start=start_from+1):
            print(f"\n{'='*60}")
            print(f"[{i}/{start_from+len(products)}] {product['name'][:50]}...")
            print(f"{'='*60}")
            
            try:
                driver.get(product['url'])
                print(f"ğŸ“ URL: {product['url']}")
                
                # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸° (ë¦¬ë·° ì»¨í…Œì´ë„ˆê°€ ë‚˜íƒ€ë‚  ë•Œê¹Œì§€)
                try:
                    WebDriverWait(driver, 10).until(
                        EC.presence_of_element_located((By.CSS_SELECTOR, "article.sdp-review__article__list"))
                    )
                    print("âœ“ í˜ì´ì§€ ë¡œë”© ì™„ë£Œ")
                    time.sleep(2)
                except:
                    print("âš ï¸ í˜ì´ì§€ ë¡œë”© íƒ€ì„ì•„ì›ƒ (ë¦¬ë·°ê°€ ì—†ì„ ìˆ˜ ìˆìŒ)")
                    fail_count += 1
                    
                    if debug_mode:
                        debug_page_structure(driver, product['name'])
                    
                    time.sleep(2)
                    continue
                
                reviews = collect_product_reviews(
                    driver, 
                    product, 
                    max_pages_per_product, 
                    collection_date,
                    debug_mode=debug_mode
                )
                
                if reviews:
                    print(f"âœ… ì™„ë£Œ: {len(reviews)}ê°œ ë¦¬ë·°")
                    success_count += 1
                    total_reviews += len(reviews)
                else:
                    print(f"âš ï¸ ì™„ë£Œ: ë¦¬ë·° ì—†ìŒ")
                    fail_count += 1
                
                time.sleep(randint(2, 4))
                
            except Exception as e:
                print(f"âŒ ì˜¤ë¥˜: {e}")
                fail_count += 1
                if debug_mode:
                    import traceback
                    traceback.print_exc()
                continue
        
        print("\n" + "="*60)
        print("ğŸ‰ ë¦¬ë·° ìˆ˜ì§‘ ì™„ë£Œ!")
        print("="*60)
        print(f"âœ… ì„±ê³µ: {success_count}ê°œ ì œí’ˆ")
        print(f"âŒ ì‹¤íŒ¨: {fail_count}ê°œ ì œí’ˆ")
        print(f"ğŸ“Š ì´ ë¦¬ë·°: {total_reviews}ê°œ")
        print("="*60)
        
    except KeyboardInterrupt:
        print(f"\n\nâš ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨ (ë§ˆì§€ë§‰ ì²˜ë¦¬: {i}ë²ˆì§¸ ì œí’ˆ)")
        print(f"ğŸ’¡ ë‹¤ìŒ ì‹¤í–‰ ì‹œ start_from={i}ë¡œ ì‹œì‘í•˜ë©´ ì´ì–´ì„œ ì§„í–‰ ê°€ëŠ¥")
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
    finally:
        driver.quit()
        print("\nğŸ”’ ë¸Œë¼ìš°ì € ì¢…ë£Œ")

#//==============================================================================//#
# ë©”ì¸ ì‹¤í–‰
#//==============================================================================//#
if __name__ == "__main__":
    # ì˜µì…˜ ì„¤ì •
    MAX_PAGES_PER_PRODUCT = None  # None = ëª¨ë“  í˜ì´ì§€, ìˆ«ì = ì œí•œ
    START_FROM = 0  # ëª‡ ë²ˆì§¸ ì œí’ˆë¶€í„° ì‹œì‘í• ì§€ (0ë¶€í„° ì‹œì‘)
    DEBUG_MODE = True  # ì²« ì œí’ˆì—ì„œ êµ¬ì¡° í™•ì¸ í›„ ì§„í–‰
    
    crawl_reviews_only(
        max_pages_per_product=MAX_PAGES_PER_PRODUCT,
        start_from=START_FROM,
        debug_mode=DEBUG_MODE
    )