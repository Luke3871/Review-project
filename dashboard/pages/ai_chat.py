#//==============================================================================//#
"""
ai_chat.py
AI ë¶„ì„ ì±—ë´‡ í˜ì´ì§€ - 3ê°€ì§€ ë²„ì „ ë¹„êµ

- V1: Rule-based Report (í†µê³„ ê¸°ë°˜ ê·œì¹™)
- V2: Multi-Agent System (Planning â†’ Execution â†’ Response)
- V3: Playbook-based Agent (ì¬ì‚¬ìš© íŒ¨í„´ + ReAct)

last_updated: 2025.10.26
"""
#//==============================================================================//#

import streamlit as st
import sys
import os

# ê²½ë¡œ ì„¤ì •
current_dir = os.path.dirname(os.path.abspath(__file__))  # pages í´ë”
dashboard_dir = os.path.dirname(current_dir)  # dashboard í´ë”
project_root = os.path.dirname(dashboard_dir)  # ReviewFW_LG_hnh í´ë”

# dashboard ê²½ë¡œ ì¶”ê°€
if dashboard_dir not in sys.path:
    sys.path.insert(0, dashboard_dir)

# analytics ê²½ë¡œ ì¶”ê°€
analytics_dir = os.path.join(project_root, 'analytics')
if analytics_dir not in sys.path:
    sys.path.insert(0, analytics_dir)

from dashboard_config import (
    load_filtered_data,
    get_available_channels,
    get_brand_list,
    get_product_list,
    PERIOD_OPTIONS
)

#//==============================================================================//#
# ì„¤ì •
#//==============================================================================//#

DB_CONFIG = {
    "dbname": os.getenv('DB_NAME', 'cosmetic_reviews'),
    "user": os.getenv('DB_USER', 'postgres'),
    "password": os.getenv('DB_PASSWORD', 'postgres'),
    "host": os.getenv('DB_HOST', 'localhost'),
    "port": int(os.getenv('DB_PORT', 5432))
}

#//==============================================================================//#
# ë©”ì¸
#//==============================================================================//#

def main():
    st.header("ğŸ¤– AI ë¶„ì„ ì—”ì§„ - ì´ì „ ëª¨ë¸")
    st.caption("V1 ~ V5 ëª¨ë¸ íˆìŠ¤í† ë¦¬")

    # 5ê°œ íƒ­
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "V1: ê·œì¹™ ê¸°ë°˜",
        "V2: LLM",
        "V3: Multi-Agent",
        "V4: ReAct",
        "V5: LangGraph"
    ])

    with tab1:
        render_v1_rulebased()

    with tab2:
        render_v2_llm_report()

    with tab3:
        render_v3_multiagent()

    with tab4:
        render_v4_playbook()

    with tab5:
        render_v5_langgraph()

#//==============================================================================//#
# V1: Rule-based Report
#//==============================================================================//#

def render_v1_rulebased():
    """V1: ê·œì¹™ ê¸°ë°˜ ë³´ê³ ì„œ"""

    st.subheader("V1: ê·œì¹™ ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸ ìƒì„±")
    st.caption("í†µê³„ ë¶„ì„ + ì¡°ê±´ë¬¸ ê·œì¹™ìœ¼ë¡œ ì¸ì‚¬ì´íŠ¸ ìë™ ìƒì„±")

    # í•„í„° ì´ˆê¸°í™”
    if 'v1_selected_channel' not in st.session_state:
        st.session_state.v1_selected_channel = None
    if 'v1_selected_brand' not in st.session_state:
        st.session_state.v1_selected_brand = None
    if 'v1_selected_product' not in st.session_state:
        st.session_state.v1_selected_product = None

    # í•„í„° UI
    st.markdown("#### ğŸ“ ì œí’ˆ ì„ íƒ")

    col1, col2, col3 = st.columns(3)

    with col1:
        channels = get_available_channels()
        if channels:
            if st.session_state.v1_selected_channel not in channels:
                st.session_state.v1_selected_channel = channels[0]

            selected_channel = st.selectbox(
                "ì±„ë„",
                channels,
                index=channels.index(st.session_state.v1_selected_channel),
                key="v1_channel"
            )
            st.session_state.v1_selected_channel = selected_channel

    with col2:
        brands = get_brand_list(st.session_state.v1_selected_channel)
        if brands:
            if st.session_state.v1_selected_brand not in brands:
                st.session_state.v1_selected_brand = brands[0]

            selected_brand = st.selectbox(
                "ë¸Œëœë“œ",
                brands,
                index=brands.index(st.session_state.v1_selected_brand),
                key="v1_brand"
            )
            st.session_state.v1_selected_brand = selected_brand

    with col3:
        products = get_product_list(
            st.session_state.v1_selected_channel,
            st.session_state.v1_selected_brand
        )
        if products:
            if st.session_state.v1_selected_product not in products:
                st.session_state.v1_selected_product = products[0]

            selected_product = st.selectbox(
                "ì œí’ˆ",
                products,
                index=products.index(st.session_state.v1_selected_product),
                key="v1_product"
            )
            st.session_state.v1_selected_product = selected_product

    # ë³´ê³ ì„œ ìƒì„± ë²„íŠ¼
    if st.button("ğŸ“Š ë¶„ì„ ë³´ê³ ì„œ ìƒì„±", type="primary", use_container_width=True, key="v1_generate"):

        with st.spinner("ë³´ê³ ì„œ ìƒì„± ì¤‘..."):
            # ë°ì´í„° ë¡œë“œ
            df = load_filtered_data(
                channel=st.session_state.v1_selected_channel,
                brand=st.session_state.v1_selected_brand,
                product=st.session_state.v1_selected_product
            )

            if df.empty:
                st.error("ì„ íƒí•œ ì œí’ˆì˜ ë¦¬ë·° ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return

            # V1 ë³´ê³ ì„œ ìƒì„±
            try:
                from ai_engines.v1_rulebased import generate_product_report

                report = generate_product_report(
                    df,
                    st.session_state.v1_selected_channel
                )

                # ë³´ê³ ì„œ í‘œì‹œ
                display_v1_report(report)

            except Exception as e:
                st.error(f"ë³´ê³ ì„œ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                import traceback
                st.code(traceback.format_exc())

def display_v1_report(report):
    """V1 ë³´ê³ ì„œ í‘œì‹œ"""

    basic_info = report.get('basic_info', {})
    satisfaction = report.get('satisfaction', {})
    keywords = report.get('keywords', {})
    trend = report.get('trend', {})
    insights = report.get('insights', [])

    # ì œëª©
    product_name = basic_info.get('product_name', 'N/A')
    st.markdown(f"# {product_name}")
    st.caption(f"ë¶„ì„ ë³´ê³ ì„œ | {report.get('generated_at', '')}")

    st.markdown("---")

    # 1. ì œí’ˆ ê°œìš”
    st.markdown("## ğŸ“‹ ì œí’ˆ ê°œìš”")

    col1, col2, col3, col4 = st.columns(4)
    col1.metric("ì´ ë¦¬ë·°", f"{basic_info.get('total_reviews', 0):,}ê°œ")
    col2.metric("ì±„ë„", basic_info.get('channel', 'N/A'))
    col3.metric("ë¸Œëœë“œ", basic_info.get('brand', 'N/A'))
    col4.metric("ê°€ê²©", basic_info.get('price', 'N/A'))

    # ì¶”ê°€ ì •ë³´
    st.caption(f"ğŸ“‚ ì¹´í…Œê³ ë¦¬: {basic_info.get('category', 'N/A')}")
    st.caption(f"ğŸ“… ë¦¬ë·° ê¸°ê°„: {basic_info.get('date_range', 'N/A')}")
    if basic_info.get('sort_type') != 'N/A':
        st.caption(f"ğŸ·ï¸ ì •ë ¬ ê¸°ì¤€: {basic_info.get('sort_type', 'N/A')}")

    st.markdown("---")

    # 2. ê³ ê° ë§Œì¡±ë„
    if satisfaction:
        st.markdown("## â­ ê³ ê° ë§Œì¡±ë„")

        col1, col2, col3 = st.columns(3)
        col1.metric(
            "ê¸ì • ë¦¬ë·°",
            f"{satisfaction['positive_ratio']}%",
            f"{satisfaction['positive_count']:,}ê°œ"
        )
        col2.metric(
            "ë¶€ì • ë¦¬ë·°",
            f"{satisfaction['negative_ratio']}%",
            f"{satisfaction['negative_count']:,}ê°œ"
        )
        col3.metric("í‰ê·  í‰ì ", f"{satisfaction['avg_rating']}/5.0")

        # í‰ì  ë¶„í¬
        import plotly.express as px

        rating_dist = satisfaction.get('rating_distribution', {})
        if rating_dist:
            fig = px.bar(
                x=list(rating_dist.keys()),
                y=list(rating_dist.values()),
                title="í‰ì  ë¶„í¬",
                labels={'x': 'í‰ì ', 'y': 'ë¦¬ë·° ìˆ˜'},
                text=list(rating_dist.values())
            )
            fig.update_traces(textposition='outside')
            fig.update_layout(height=300, showlegend=False)
            st.plotly_chart(fig, use_container_width=True)

        st.markdown("---")

    # 3. í‚¤ì›Œë“œ ë¶„ì„
    if keywords:
        st.markdown("## ğŸ’¬ ì£¼ìš” í‚¤ì›Œë“œ")

        # ì „ì²´ í‚¤ì›Œë“œ (ê¸ì •/ë¶€ì • êµ¬ë¶„ ì—†ì´)
        overall_keywords = keywords.get('overall_top10', [])
        if overall_keywords:
            st.markdown("### ğŸ“Š ì „ì²´ í‚¤ì›Œë“œ TOP 10")

            # 2ì—´ë¡œ í‘œì‹œ
            col1, col2 = st.columns(2)

            with col1:
                for i, (kw, freq) in enumerate(overall_keywords[:5], 1):
                    st.markdown(f"{i}. **{kw}** ({freq}íšŒ)")

            with col2:
                for i, (kw, freq) in enumerate(overall_keywords[5:], 6):
                    st.markdown(f"{i}. **{kw}** ({freq}íšŒ)")

            st.markdown("---")

        # ê¸ì •/ë¶€ì • í‚¤ì›Œë“œ
        positive_keywords = keywords.get('positive_top5', [])
        negative_keywords = keywords.get('negative_top5', [])

        if positive_keywords or negative_keywords:
            st.markdown("### ğŸ” ê°ì •ë³„ í‚¤ì›Œë“œ ë¶„ì„")

            col1, col2 = st.columns(2)

            with col1:
                st.markdown("**âœ… ê¸ì • í‚¤ì›Œë“œ TOP 5**")
                if positive_keywords:
                    for i, (kw, freq) in enumerate(positive_keywords, 1):
                        st.markdown(f"{i}. **{kw}** ({freq}íšŒ)")
                else:
                    st.info("ê¸ì • í‚¤ì›Œë“œ ì—†ìŒ (ë¶€ì • ë¦¬ë·°ë§Œ ì¡´ì¬)")

            with col2:
                st.markdown("**âŒ ë¶€ì • í‚¤ì›Œë“œ TOP 5**")
                if negative_keywords:
                    for i, (kw, freq) in enumerate(negative_keywords, 1):
                        st.markdown(f"{i}. **{kw}** ({freq}íšŒ)")
                else:
                    st.info("ë¶€ì • í‚¤ì›Œë“œ ì—†ìŒ (ê¸ì • ë¦¬ë·°ë§Œ ì¡´ì¬)")

        st.markdown("---")

    # 4. íŠ¸ë Œë“œ ìš”ì•½
    if trend:
        st.markdown("## ğŸ“ˆ íŠ¸ë Œë“œ ìš”ì•½")

        col1, col2, col3 = st.columns(3)
        col1.metric("ìµœê³  ë¦¬ë·° ë‹¬", trend.get('peak_month', 'N/A'), f"{trend.get('peak_count', 0)}ê°œ")
        col2.metric("ìµœê·¼ ë¦¬ë·° ë‹¬", trend.get('recent_month', 'N/A'), f"{trend.get('recent_count', 0)}ê°œ")
        col3.metric("ìµœê·¼ íŠ¸ë Œë“œ", trend.get('trend_direction', 'N/A'))

        st.markdown("---")

    # 5. í•µì‹¬ ì¸ì‚¬ì´íŠ¸ (ê·œì¹™ ê¸°ë°˜)
    st.markdown("## ğŸ’¡ í•µì‹¬ ì¸ì‚¬ì´íŠ¸")

    if insights:
        for insight in insights:
            st.markdown(f"- {insight}")
    else:
        st.info("ìƒì„±ëœ ì¸ì‚¬ì´íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")

    st.markdown("---")

    # ë³´ê³ ì„œ ì •ë³´
    st.caption(f"ğŸ“Š V1 Rule-based Report | {report.get('generated_at', '')}")
    st.caption(f"ğŸ“¦ ë°ì´í„° ì¶œì²˜: {basic_info.get('channel', 'N/A')}")

#//==============================================================================//#
# V2: LLM Report
#//==============================================================================//#

def render_v2_llm_report():
    """V2: LLM ê¸°ë°˜ ë³´ê³ ì„œ"""

    st.subheader("V2: LLM ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸ ìƒì„±")
    st.caption("GPTë¥¼ í™œìš©í•œ ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ ìë™ ìƒì„±")

    # í•„í„° ì´ˆê¸°í™”
    if 'v2_selected_channel' not in st.session_state:
        st.session_state.v2_selected_channel = None
    if 'v2_selected_brand' not in st.session_state:
        st.session_state.v2_selected_brand = None
    if 'v2_selected_product' not in st.session_state:
        st.session_state.v2_selected_product = None
    if 'v2_api_key' not in st.session_state:
        st.session_state.v2_api_key = ""

    # API í‚¤ ì…ë ¥
    st.markdown("#### ğŸ”‘ API ì„¤ì •")
    api_key = st.text_input(
        "OpenAI API Key",
        value=st.session_state.v2_api_key,
        type="password",
        help="GPT ë¶„ì„ì„ ìœ„í•´ OpenAI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤",
        key="v2_api_input"
    )
    st.session_state.v2_api_key = api_key

    if not api_key:
        st.warning("âš ï¸ API í‚¤ë¥¼ ì…ë ¥í•´ì•¼ LLM ë³´ê³ ì„œë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    else:
        st.success("âœ… API í‚¤ ì„¤ì • ì™„ë£Œ")

    st.markdown("---")

    # í•„í„° UI
    st.markdown("#### ğŸ“ ì œí’ˆ ì„ íƒ")

    col1, col2, col3 = st.columns(3)

    with col1:
        channels = get_available_channels()
        if channels:
            if st.session_state.v2_selected_channel not in channels:
                st.session_state.v2_selected_channel = channels[0]

            selected_channel = st.selectbox(
                "ì±„ë„",
                channels,
                index=channels.index(st.session_state.v2_selected_channel),
                key="v2_channel"
            )
            st.session_state.v2_selected_channel = selected_channel

    with col2:
        brands = get_brand_list(st.session_state.v2_selected_channel)
        if brands:
            if st.session_state.v2_selected_brand not in brands:
                st.session_state.v2_selected_brand = brands[0]

            selected_brand = st.selectbox(
                "ë¸Œëœë“œ",
                brands,
                index=brands.index(st.session_state.v2_selected_brand),
                key="v2_brand"
            )
            st.session_state.v2_selected_brand = selected_brand

    with col3:
        products = get_product_list(
            st.session_state.v2_selected_channel,
            st.session_state.v2_selected_brand
        )
        if products:
            if st.session_state.v2_selected_product not in products:
                st.session_state.v2_selected_product = products[0]

            selected_product = st.selectbox(
                "ì œí’ˆ",
                products,
                index=products.index(st.session_state.v2_selected_product),
                key="v2_product"
            )
            st.session_state.v2_selected_product = selected_product

    # LLM ë³´ê³ ì„œ ìƒì„± ë²„íŠ¼ (2ê°€ì§€ ë°©ì‹)
    st.markdown("#### ğŸ¤– AI ë¶„ì„ ì‹¤í–‰")

    col1, col2 = st.columns(2)

    with col1:
        v2a_button = st.button(
            "ğŸ“Š V2-A: ë°ì´í„° ì§ì ‘ ë¶„ì„",
            type="primary",
            use_container_width=True,
            key="v2a_generate",
            help="ë¦¬ë·° ë°ì´í„°ë¥¼ GPTê°€ ì§ì ‘ ë¶„ì„í•˜ì—¬ ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ ìƒì„±"
        )

    with col2:
        v2b_button = st.button(
            "ğŸ”‘ V2-B: í‚¤ì›Œë“œ í•´ì„ ë¶„ì„",
            type="primary",
            use_container_width=True,
            key="v2b_generate",
            help="í‚¤ì›Œë“œë¥¼ ë¨¼ì € ì¶”ì¶œí•œ í›„ GPTê°€ í•´ì„ ë° ì¡°ì–¸ ìƒì„±"
        )

    # V2-A ì‹¤í–‰
    if v2a_button:

        if not st.session_state.v2_api_key:
            st.error("ë¨¼ì € API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
            return

        with st.spinner("AIê°€ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ì¸ì‚¬ì´íŠ¸ë¥¼ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
            # ë°ì´í„° ë¡œë“œ
            df = load_filtered_data(
                channel=st.session_state.v2_selected_channel,
                brand=st.session_state.v2_selected_brand,
                product=st.session_state.v2_selected_product
            )

            if df.empty:
                st.error("ì„ íƒí•œ ì œí’ˆì˜ ë¦¬ë·° ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return

            # V2 LLM ë³´ê³ ì„œ ìƒì„±
            try:
                from ai_engines.v2_llm_report import generate_llm_report

                report = generate_llm_report(
                    df,
                    st.session_state.v2_selected_channel,
                    st.session_state.v2_api_key
                )

                # ë³´ê³ ì„œ í‘œì‹œ
                display_v2_report(report)

            except Exception as e:
                st.error(f"LLM ë³´ê³ ì„œ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                import traceback
                st.code(traceback.format_exc())

    # V2-B ì‹¤í–‰
    if v2b_button:

        if not st.session_state.v2_api_key:
            st.error("ë¨¼ì € API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
            return

        with st.spinner("í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ê³  AIê°€ í•´ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
            # ë°ì´í„° ë¡œë“œ
            df = load_filtered_data(
                channel=st.session_state.v2_selected_channel,
                brand=st.session_state.v2_selected_brand,
                product=st.session_state.v2_selected_product
            )

            if df.empty:
                st.error("ì„ íƒí•œ ì œí’ˆì˜ ë¦¬ë·° ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return

            # V2-B í‚¤ì›Œë“œ í•´ì„ ë¶„ì„
            try:
                # 1. ë¨¼ì € í‚¤ì›Œë“œ ì¶”ì¶œ
                from ai_engines.v1_rulebased.keyword_analyzer import extract_overall_keywords

                keywords = extract_overall_keywords(df, st.session_state.v2_selected_channel)

                if not keywords:
                    st.error("í‚¤ì›Œë“œ ì¶”ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                    return

                # 2. GPTë¡œ í‚¤ì›Œë“œ í•´ì„
                from ai_engines.v2_llm_report.keyword_interpreter import generate_keyword_interpretation

                report = generate_keyword_interpretation(
                    df,
                    keywords,
                    st.session_state.v2_selected_channel,
                    st.session_state.v2_api_key
                )

                # ë³´ê³ ì„œ í‘œì‹œ
                display_v2b_report(report, keywords)

            except Exception as e:
                st.error(f"í‚¤ì›Œë“œ í•´ì„ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                import traceback
                st.code(traceback.format_exc())


def display_v2_report(report):
    """V2 LLM ë³´ê³ ì„œ í‘œì‹œ"""

    if not report:
        st.error("ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨")
        return

    # ì—ëŸ¬ ì²˜ë¦¬
    if 'error' in report and report['error']:
        st.error(f"AI ë¶„ì„ ì˜¤ë¥˜: {report['error']}")
        return

    # ì œëª©
    product_name = report.get('product_name', 'N/A')
    brand = report.get('brand', 'N/A')
    channel = report.get('channel', 'N/A')

    st.markdown(f"# ğŸ¤– AI ë¶„ì„ ë³´ê³ ì„œ")
    st.markdown(f"## {brand} - {product_name}")
    st.caption(f"ìƒì„±ì¼ì‹œ: {report.get('generated_at', '')} | ì±„ë„: {channel}")

    st.markdown("---")

    # 1. ë°ì´í„° ìš”ì•½
    summary = report.get('summary')
    if summary:
        st.markdown("## ğŸ“Š ë°ì´í„° ìš”ì•½")
        st.markdown(summary)
        st.markdown("---")

    # 2. AI ì¸ì‚¬ì´íŠ¸
    insights = report.get('insights')
    if insights:
        st.markdown("## ğŸ’¡ AI ìƒì„± ì¸ì‚¬ì´íŠ¸")
        st.markdown(insights)
    else:
        st.warning("AI ì¸ì‚¬ì´íŠ¸ë¥¼ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

    st.markdown("---")

    # ë³´ê³ ì„œ ì •ë³´
    st.caption(f"ğŸ¤– V2-A LLM Report (GPT-4o-mini) | {report.get('generated_at', '')}")
    st.caption(f"ğŸ“¦ ë°ì´í„° ì¶œì²˜: {channel}")


def display_v2b_report(report, keywords):
    """V2-B í‚¤ì›Œë“œ í•´ì„ ë³´ê³ ì„œ í‘œì‹œ"""

    if not report:
        st.error("ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨")
        return

    # ì—ëŸ¬ ì²˜ë¦¬
    if 'error' in report and report['error']:
        st.error(f"AI ë¶„ì„ ì˜¤ë¥˜: {report['error']}")
        return

    # ì œëª©
    product_name = report.get('product_name', 'N/A')
    brand = report.get('brand', 'N/A')
    channel = report.get('channel', 'N/A')

    st.markdown(f"# ğŸ”‘ AI í‚¤ì›Œë“œ í•´ì„ ë³´ê³ ì„œ")
    st.markdown(f"## {brand} - {product_name}")
    st.caption(f"ìƒì„±ì¼ì‹œ: {report.get('generated_at', '')} | ì±„ë„: {channel}")

    st.markdown("---")

    # 1. ê¸°ë³¸ ì •ë³´
    st.markdown("## ğŸ“Š ë¶„ì„ ê¸°ë³¸ ì •ë³´")

    col1, col2, col3 = st.columns(3)
    col1.metric("ì´ ë¦¬ë·° ìˆ˜", f"{report.get('total_reviews', 0):,}ê°œ")
    col2.metric("í‰ê·  í‰ì ", f"{report.get('avg_rating', 0):.2f}/5.0")
    col3.metric("ê¸ì • ë¹„ìœ¨", f"{report.get('positive_ratio', 0):.1f}%")

    st.markdown("---")

    # 2. ì¶”ì¶œëœ í‚¤ì›Œë“œ TOP 20
    st.markdown("## ğŸ”‘ ì¶”ì¶œëœ í‚¤ì›Œë“œ TOP 20")

    keywords_summary = report.get('keywords_summary', [])
    if keywords_summary:
        # ë””ë²„ê¹…: í‚¤ì›Œë“œ ê°œìˆ˜ í™•ì¸
        st.caption(f"ì´ {len(keywords_summary)}ê°œ í‚¤ì›Œë“œ")
        # í…Œì´ë¸” í˜•íƒœë¡œ í‘œì‹œ
        import pandas as pd

        # í‚¤ì›Œë“œ ë°ì´í„° íŒŒì‹± (í˜•ì‹: "í‚¤ì›Œë“œ: ì ìˆ˜")
        keyword_data = []
        for i, kw_str in enumerate(keywords_summary[:20], 1):
            if ':' in kw_str:
                keyword, score = kw_str.split(':', 1)
                keyword_data.append({
                    'ìˆœìœ„': i,
                    'í‚¤ì›Œë“œ': keyword.strip(),
                    'ì¤‘ìš”ë„': float(score.strip())
                })
            else:
                keyword_data.append({
                    'ìˆœìœ„': i,
                    'í‚¤ì›Œë“œ': kw_str.strip(),
                    'ì¤‘ìš”ë„': 0.0
                })

        # DataFrame ìƒì„±
        df_keywords = pd.DataFrame(keyword_data)

        # 2ì—´ë¡œ ë‚˜ëˆ ì„œ í‘œì‹œ
        col1, col2 = st.columns(2)

        with col1:
            st.markdown("**1-10ìœ„**")
            st.dataframe(
                df_keywords.iloc[:10],
                use_container_width=True,
                hide_index=True
            )

        with col2:
            st.markdown("**11-20ìœ„**")
            st.dataframe(
                df_keywords.iloc[10:20],
                use_container_width=True,
                hide_index=True
            )
    else:
        st.info("í‚¤ì›Œë“œ ìš”ì•½ ì—†ìŒ")

    st.markdown("---")

    # 3. AI í•´ì„
    interpretation = report.get('interpretation')
    if interpretation:
        st.markdown("## ğŸ’¡ AI í‚¤ì›Œë“œ í•´ì„ ë° ì¡°ì–¸")
        st.markdown(interpretation)
    else:
        st.warning("AI í•´ì„ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

    st.markdown("---")

    # ë³´ê³ ì„œ ì •ë³´
    st.caption(f"ğŸ”‘ V2-B Keyword Interpretation Report (GPT-4o-mini) | {report.get('generated_at', '')}")
    st.caption(f"ğŸ“¦ ë°ì´í„° ì¶œì²˜: {channel}")

#//==============================================================================//#
# V3: Multi-Agent
#//==============================================================================//#

def render_v3_multiagent():
    """V3: Multi-Agent System (ì±—ë´‡ ìŠ¤íƒ€ì¼)"""

    st.subheader("V3: Multi-Agent System")
    st.caption("PlanningAgent â†’ ExecutionAgent â†’ ResponseAgent (ë²¡í„° ê²€ìƒ‰ + í•„í„° ê²€ìƒ‰)")

    st.markdown("""
    ### ğŸ’¡ ë™ì‘ ë°©ì‹
    1. **PlanningAgent**: GPTê°€ ì‚¬ìš©ì ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ì‹¤í–‰ ê³„íš ìƒì„±
    2. **ExecutionAgent**: ê³„íšì— ë”°ë¼ PostgreSQL + pgvector ê²€ìƒ‰ (BGE-M3 ì„ë² ë”©)
    3. **ResponseAgent**: GPTê°€ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ìì—°ì–´ ë‹µë³€ìœ¼ë¡œ ë³€í™˜

    ### ğŸ“ ì˜ˆì‹œ ì§ˆë¬¸
    - "VT ì‹œì¹´í¬ë¦¼ ë³´ìŠµë ¥ ì–´ë•Œ?" (ë²¡í„° ê²€ìƒ‰)
    - "ì˜¬ë¦¬ë¸Œì˜ í‰ì  ë†’ì€ ì œí’ˆì€?" (í•„í„° ê²€ìƒ‰ + í†µê³„)
    - "ìµœê·¼ 3ê°œì›” í† ë¦¬ë“  í‰ê°€ëŠ”?" (ë²¡í„° ê²€ìƒ‰ + ë‚ ì§œ í•„í„°)
    - "ë³µí•©ì„± í”¼ë¶€ì— ì¢‹ì€ ì œí’ˆ" (í•„í„° ê²€ìƒ‰ + í”¼ë¶€ íƒ€ì…)
    """)

    st.markdown("---")

    # API í‚¤ ì…ë ¥ (ì„¸ì…˜ ìƒíƒœ)
    if 'v3_api_key' not in st.session_state:
        st.session_state.v3_api_key = ""

    api_key = st.text_input(
        "OpenAI API Key",
        value=st.session_state.v3_api_key,
        type="password",
        help="Planning Agentì™€ Response Agentì—ì„œ GPT-4o-mini ì‚¬ìš©",
        key="v3_api_input"
    )

    if api_key:
        st.session_state.v3_api_key = api_key
        st.success("âœ… API í‚¤ ì„¤ì • ì™„ë£Œ")
    else:
        st.warning("âš ï¸ API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”")

    st.markdown("---")

    # ì±„íŒ… íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”
    if 'v3_messages' not in st.session_state:
        st.session_state.v3_messages = []

    # ì´ì „ ë©”ì‹œì§€ í‘œì‹œ
    for msg in st.session_state.v3_messages:
        with st.chat_message(msg['role']):
            st.markdown(msg['content'])

    # ì‚¬ìš©ì ì…ë ¥ (ì±—ë´‡ ìŠ¤íƒ€ì¼)
    if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: VT ì‹œì¹´í¬ë¦¼ ë³´ìŠµë ¥ ì–´ë•Œ?)"):

        if not st.session_state.v3_api_key:
            st.error("âŒ ë¨¼ì € API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”")
            return

        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        st.session_state.v3_messages.append({'role': 'user', 'content': prompt})

        with st.chat_message('user'):
            st.markdown(prompt)

        # AI ì‘ë‹µ
        with st.chat_message('assistant'):
            with st.spinner('ğŸ¤– Multi-Agent ì‹œìŠ¤í…œ ë¶„ì„ ì¤‘...'):
                try:
                    from ai_engines.v3_multi_agent import Orchestrator

                    orchestrator = Orchestrator(st.session_state.v3_api_key)
                    result = orchestrator.process_query(prompt)

                    # ë‹µë³€ í‘œì‹œ
                    st.markdown(result['answer'])

                    # ë””ë²„ê·¸ ì •ë³´ (Expander)
                    with st.expander("ğŸ” ì‹¤í–‰ ê³„íš ë³´ê¸°"):
                        st.json(result['plan'])

                    with st.expander("ğŸ“ ì‹¤í–‰ ê²°ê³¼ ë³´ê¸°"):
                        if result['results']:
                            if result['results'].get('reviews') is not None:
                                reviews = result['results']['reviews']
                                if not reviews.empty:
                                    st.write(f"ê²€ìƒ‰ëœ ë¦¬ë·°: {len(reviews)}ê°œ")
                                    st.dataframe(reviews.head(10))

                            if result['results'].get('stats'):
                                st.write("í†µê³„ ì •ë³´:")
                                st.json(result['results']['stats'])

                    # ì‘ë‹µ ì €ì¥
                    st.session_state.v3_messages.append({
                        'role': 'assistant',
                        'content': result['answer']
                    })

                except Exception as e:
                    error_msg = f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}"
                    st.error(error_msg)
                    import traceback
                    with st.expander("ìƒì„¸ ì˜¤ë¥˜ ì •ë³´"):
                        st.code(traceback.format_exc())

                    # ì˜¤ë¥˜ë„ íˆìŠ¤í† ë¦¬ì— ì €ì¥
                    st.session_state.v3_messages.append({
                        'role': 'assistant',
                        'content': error_msg
                    })

#//==============================================================================//#
# V4: Playbook Agent
#//==============================================================================//#

def render_v4_playbook():
    """V4: ReAct Agent (ê³„ì¸µì  ê²€ìƒ‰ + Map-Reduce)"""

    st.subheader("V4: ReAct Agent")
    st.caption("ê³„ì¸µì  ê²€ìƒ‰(Vectorâ†’BM25â†’Hybrid) + Map-Reduce ìš”ì•½ìœ¼ë¡œ ê³ í’ˆì§ˆ ì¸ì‚¬ì´íŠ¸ ìƒì„±")

    # API í‚¤ ì…ë ¥ (ë©”ì¸ ì˜ì—­)
    st.markdown("#### ğŸ”‘ API ì„¤ì •")

    # API í‚¤ ì´ˆê¸°í™”
    if 'v4_api_key' not in st.session_state:
        st.session_state.v4_api_key = ""

    api_key = st.text_input(
        "OpenAI API Key",
        value=st.session_state.v4_api_key,
        type="password",
        help="QueryHandlerì™€ Map-Reduceì—ì„œ GPT-4o-mini ì‚¬ìš©",
        key="v4_api_input"
    )

    if api_key:
        st.session_state.v4_api_key = api_key
        st.success("âœ… API í‚¤ ì„¤ì • ì™„ë£Œ")
    else:
        st.warning("âš ï¸ API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”")

    st.markdown("---")

    # ë™ì‘ ë°©ì‹ ë° ì˜ˆì‹œ ì§ˆë¬¸ (Expanderë¡œ ì •ë¦¬)
    with st.expander("ğŸ’¡ ë™ì‘ ë°©ì‹ ë° ì˜ˆì‹œ ì§ˆë¬¸"):
        st.markdown("### ë™ì‘ ë°©ì‹")
        st.markdown("""
        **ê³„ì¸µì  ê²€ìƒ‰ (3ë‹¨ê³„)**
        1. Vector ê²€ìƒ‰ (BGE-M3)
        2. BM25 ì¬ì •ë ¬
        3. Hybrid ìµœì¢… ì„ ë³„

        **Map-Reduce ìš”ì•½**
        - 200ê±´ â†’ 10ê°œ ê·¸ë£¹ ìš”ì•½
        - ìµœì¢… í†µí•© ë³´ê³ ì„œ ìƒì„±
        """)

        st.markdown("### ğŸ“ ì˜ˆì‹œ ì§ˆë¬¸")
        st.markdown("""
        - "í† ë¦¬ë“  ì „ë°˜ì ìœ¼ë¡œ ì–´ë•Œ?"
        - "VT ì‹œì¹´í¬ë¦¼ ë³´ìŠµë ¥ ì–´ë•Œ?"
        - "ì˜¬ë¦¬ë¸Œì˜ì´ë‘ ì¿ íŒ¡ì—ì„œ ë– ì˜¤ë¥´ëŠ” í‚¤ì›Œë“œ ë­ì•¼?"
        - "ë¼ìš´ë“œë©ì´ë‘ í† ë¦¬ë“  ë¹„êµí•´ì¤˜"
        """)

    st.markdown("---")

    # ì±„íŒ… íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”
    if 'v4_messages' not in st.session_state:
        st.session_state.v4_messages = []

    # ëª¨ë“  ë©”ì‹œì§€ í‘œì‹œ (ì •ìˆœ: ì˜¤ë˜ëœ ê²ƒ â†’ ìµœì‹  ê²ƒ)
    for msg in st.session_state.v4_messages:
        with st.chat_message(msg['role']):
            st.markdown(msg['content'])

    # ì‚¬ìš©ì ì…ë ¥ (ì±—ë´‡ ìŠ¤íƒ€ì¼)
    if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: í† ë¦¬ë“  ì „ë°˜ì ìœ¼ë¡œ ì–´ë•Œ?)"):

        if not st.session_state.v4_api_key:
            st.error("âŒ ë¨¼ì € API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”")
            return

        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        st.session_state.v4_messages.append({'role': 'user', 'content': prompt})

        with st.chat_message('user'):
            st.markdown(prompt)

        # AI ì‘ë‹µ
        with st.chat_message('assistant'):
            try:
                from ai_engines.v4_react_agent import Orchestrator

                orchestrator = Orchestrator(st.session_state.v4_api_key)

                # ì§„í–‰ìƒí™©ì„ ì±„íŒ…ì°½ì— ëˆ„ì  í‘œì‹œ
                def progress_callback(event, data):
                    """ì§„í–‰ìƒí™© ì½œë°± - ì±„íŒ…ì°½ì— ë©”ì‹œì§€ ì¶”ê°€"""
                    if event == 'query_parsing_start':
                        st.write("ğŸ¤” ì§ˆë¬¸ ë¶„ì„ ì¤‘...")
                    elif event == 'query_parsing_done':
                        intent_msg = orchestrator.create_intent_message(data)
                        st.success(intent_msg)
                    elif event == 'stage1_start':
                        st.write("ğŸ” **Stage 1: Vector ê²€ìƒ‰ ì¤‘...**")
                    elif event == 'stage1_done':
                        st.success(f"âœ… Stage 1: {data:,}ê±´ ë°œê²¬")
                    elif event == 'stage2_start':
                        st.write("ğŸ¯ **Stage 2: BM25 ì¬ì •ë ¬ ì¤‘...**")
                    elif event == 'stage2_done':
                        st.success(f"âœ… Stage 2: {data:,}ê±´ ì„ ë³„")
                    elif event == 'stage3_start':
                        st.write("â­ **Stage 3: Hybrid ìµœì¢… ì„ ë³„ ì¤‘...**")
                    elif event == 'stage3_done':
                        st.success(f"âœ… Stage 3: {data:,}ê±´ ìµœì¢… ì„ ë³„")
                    elif event == 'map_reduce_start':
                        chunks = (data + 19) // 20  # ceil(data / 20)
                        st.write(f"ğŸ“ **Map-Reduce ì‹œì‘:** {data}ê°œ ë¦¬ë·°ë¥¼ {chunks}ê°œ ê·¸ë£¹ìœ¼ë¡œ ìš”ì•½")
                    elif event == 'map_progress':
                        current, total = data
                        st.write(f"   â””â”€ ê·¸ë£¹ {current}/{total} ìš”ì•½ ì¤‘...")
                    elif event == 'reduce_start':
                        st.write(f"ğŸ”„ **Reduce:** {data}ê°œ ê·¸ë£¹ ìš”ì•½ì„ í†µí•©í•˜ì—¬ ìµœì¢… ë³´ê³ ì„œ ì‘ì„± ì¤‘...")
                    elif event == 'map_reduce_done':
                        st.success("âœ… ìµœì¢… ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ!")

                # ì‹¤í–‰
                result = orchestrator.process_query(prompt, progress_callback)

                # êµ¬ë¶„ì„  ì¶”ê°€
                st.markdown("---")

                # ë‹µë³€ í‘œì‹œ
                st.markdown(result['answer'])

                # ë””ë²„ê·¸ ì •ë³´ (Expander)
                with st.expander("ğŸ” ë¶„ì„ ì •ë³´ ë³´ê¸°"):
                    st.write("**íŒŒì‹±ëœ ì¿¼ë¦¬:**")
                    st.json(result['parsed'])

                    st.write("**í†µê³„:**")
                    st.write(f"- Stage 1: {result['stats']['stage1']:,}ê±´")
                    st.write(f"- Stage 2: {result['stats']['stage2']:,}ê±´")
                    st.write(f"- Stage 3 (ìµœì¢…): {result['stats']['stage3']:,}ê±´")

                    st.write("**Playbook:**")
                    st.json(result['playbook'])

                # ì‘ë‹µ ì €ì¥
                st.session_state.v4_messages.append({
                    'role': 'assistant',
                    'content': result['answer']
                })

            except Exception as e:
                error_msg = f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}"
                st.error(error_msg)
                import traceback
                with st.expander("ìƒì„¸ ì˜¤ë¥˜ ì •ë³´"):
                    st.code(traceback.format_exc())

                # ì˜¤ë¥˜ë„ íˆìŠ¤í† ë¦¬ì— ì €ì¥
                st.session_state.v4_messages.append({
                    'role': 'assistant',
                    'content': error_msg
                })

#//==============================================================================//#
# V5: LangGraph Agent
#//==============================================================================//#

def render_v5_langgraph():
    """V5: LangGraph Agent (14ê°œ Tool + 5ê°œ Node)"""

    st.subheader("V5: LangGraph Agent")

    # API í‚¤ ì´ˆê¸°í™”
    if 'v5_api_key' not in st.session_state:
        st.session_state.v5_api_key = ""

    # API í‚¤ ì…ë ¥
    api_key = st.text_input(
        "OpenAI API Key",
        value=st.session_state.v5_api_key,
        type="password",
        help="Parserì™€ Synthesizer Nodeì—ì„œ GPT ì‚¬ìš©",
        key="v5_api_input"
    )

    if api_key:
        st.session_state.v5_api_key = api_key
        st.success("âœ… API í‚¤ ì„¤ì • ì™„ë£Œ")
    else:
        st.warning("âš ï¸ API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”")

    st.markdown("---")

    # ì±„íŒ… íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”
    if 'v5_messages' not in st.session_state:
        st.session_state.v5_messages = []

    # ì¬ì§ˆë¬¸ìš© ìƒíƒœ ì´ˆê¸°í™”
    if 'v5_pending_query' not in st.session_state:
        st.session_state.v5_pending_query = None

    # ëª¨ë“  ë©”ì‹œì§€ í‘œì‹œ (ì •ìˆœ: ì˜¤ë˜ëœ ê²ƒ â†’ ìµœì‹  ê²ƒ, ì…ë ¥ì°½ì´ ë§¨ ë°‘ì— ì˜¤ë„ë¡)
    for msg in st.session_state.v5_messages:
        with st.chat_message(msg['role']):
            st.markdown(msg['content'])

            # ì¬ì§ˆë¬¸ ë“œë¡­ë‹¤ìš´ì´ ìˆëŠ” ê²½ìš° í‘œì‹œ
            if msg.get('show_dropdowns'):
                st.markdown("---")

                available_channels = msg.get('available_channels', [])
                available_brands = msg.get('available_brands', [])
                available_products = msg.get('available_products', [])

                # ë“œë¡­ë‹¤ìš´ 3ê°œ
                col1, col2, col3 = st.columns(3)

                with col1:
                    selected_channel = st.selectbox(
                        "ì±„ë„ ì„ íƒ",
                        options=["ì „ì²´"] + available_channels,
                        key=f"v5_channel_{msg['msg_id']}"
                    )

                with col2:
                    selected_brand = st.selectbox(
                        "ë¸Œëœë“œ ì„ íƒ",
                        options=["ì „ì²´"] + available_brands,
                        key=f"v5_brand_{msg['msg_id']}"
                    )

                with col3:
                    selected_product = st.selectbox(
                        "ì œí’ˆ ì„ íƒ",
                        options=["ì „ì²´"] + available_products,
                        key=f"v5_product_{msg['msg_id']}"
                    )

                # ë¶„ì„ ì‹¤í–‰ ë²„íŠ¼
                if st.button("ì„ íƒ ì™„ë£Œ - ë¶„ì„ ì‹œì‘", key=f"v5_analyze_{msg['msg_id']}"):
                    # ì„ íƒëœ ê°’ìœ¼ë¡œ ìƒˆ ì¿¼ë¦¬ ìƒì„±
                    intent_map = {
                        'attribute_analysis': 'ì†ì„± ë¶„ì„í•´ì¤˜',
                        'pros_cons': 'ì¥ë‹¨ì  ì•Œë ¤ì¤˜',
                        'sentiment_analysis': 'ê°ì„± ë¶„ì„í•´ì¤˜',
                        'comparison': 'ë¹„êµí•´ì¤˜',
                        'full_review': 'ë¶„ì„í•´ì¤˜'
                    }
                    intent = msg.get('parsed_query', {}).get('intent', 'full_review')
                    intent_text = intent_map.get(intent, 'ë¶„ì„í•´ì¤˜')

                    query_parts = []
                    if selected_channel != "ì „ì²´":
                        query_parts.append(selected_channel)
                    if selected_brand != "ì „ì²´":
                        query_parts.append(selected_brand)
                    if selected_product != "ì „ì²´":
                        query_parts.append(selected_product)
                    query_parts.append(intent_text)

                    new_query = " ".join(query_parts)
                    st.session_state.v5_pending_query = new_query
                    st.rerun()

    # ì‚¬ìš©ì ì…ë ¥ (ì±—ë´‡ ìŠ¤íƒ€ì¼, í•˜ë‹¨ ê³ ì •) - í•­ìƒ í‘œì‹œ
    user_input = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ë¹Œë¦¬í”„ ë¸Œëœë“œ ì†ì„± ë¶„ì„í•´ì¤˜)")

    # Pending query í™•ì¸ (ë“œë¡­ë‹¤ìš´ ì¬ì§ˆë¬¸)
    if st.session_state.v5_pending_query:
        prompt = st.session_state.v5_pending_query
        st.session_state.v5_pending_query = None
    else:
        prompt = user_input

    if prompt:

        if not st.session_state.v5_api_key:
            st.error("âŒ ë¨¼ì € API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”")
            return

        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        st.session_state.v5_messages.append({'role': 'user', 'content': prompt})

        with st.chat_message('user'):
            st.markdown(prompt)

        # AI ì‘ë‹µ
        with st.chat_message('assistant'):
            try:
                # V5 Agent import
                import os
                ai_engines_dir = os.path.join(dashboard_dir, 'ai_engines')
                if ai_engines_dir not in sys.path:
                    sys.path.insert(0, ai_engines_dir)

                from v5_langgraph_agent import V5Agent

                # Agent ì´ˆê¸°í™” (API í‚¤ í™˜ê²½ë³€ìˆ˜ ì„¤ì •)
                os.environ['OPENAI_API_KEY'] = st.session_state.v5_api_key

                agent = V5Agent()

                # ì§„í–‰ ìƒí™© í‘œì‹œìš© ì»¨í…Œì´ë„ˆ
                progress_container = st.container()

                # ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ì‹¤í–‰í•˜ì—¬ ê° ë…¸ë“œ ì¶œë ¥ í‘œì‹œ
                with progress_container:
                    st.write("ğŸ¤– **LangGraph ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì¤‘...**\n")

                    node_icons = {
                        "Parser": "ğŸ”",
                        "Validation": "âœ…",
                        "Router": "ğŸ¯",
                        "Executor": "âš™ï¸",
                        "Synthesizer": "ğŸ“"
                    }

                    status_icons = {
                        "processing": "ğŸ”„",
                        "success": "âœ…",
                        "warning": "âš ï¸",
                        "error": "âŒ",
                        "info": "â„¹ï¸"
                    }

                    final_state = None

                    for state_update in agent.stream(prompt):
                        # í˜„ì¬ ë…¸ë“œ ìƒíƒœ í™•ì¸
                        node_name = list(state_update.keys())[0]
                        node_state = state_update[node_name]

                        messages = node_state.get("messages", [])
                        if messages:
                            latest_msg = messages[-1]
                            node_icon = node_icons.get(latest_msg['node'], "â€¢")
                            status_icon = status_icons.get(latest_msg['status'], "â€¢")

                            # ë…¸ë“œ ì§„í–‰ ìƒí™© ì¶œë ¥
                            status_text = f"{node_icon} **{latest_msg['node']}** {status_icon}"
                            st.write(status_text)

                            # contentê°€ ì§§ìœ¼ë©´ ì „ì²´ ì¶œë ¥, ê¸¸ë©´ ìš”ì•½
                            content = latest_msg['content']
                            if len(content) <= 150:
                                st.caption(content)
                            else:
                                # ì—¬ëŸ¬ ì¤„ì¸ ê²½ìš° ì²« ì¤„ë§Œ í‘œì‹œ
                                first_line = content.split('\n')[0]
                                st.caption(f"{first_line}...")

                        # ë§ˆì§€ë§‰ ìƒíƒœ ì €ì¥
                        final_state = node_state

                # êµ¬ë¶„ì„ 
                st.markdown("---")

                # ìµœì¢… ì‘ë‹µ ì „ì²´ ì‹¤í–‰ (final_response ê°€ì ¸ì˜¤ê¸°)
                if final_state is None:
                    final_state = agent.run(prompt)

                # ìµœì¢… ì‘ë‹µ í‘œì‹œ
                final_response = final_state.get('final_response', 'ì‘ë‹µ ìƒì„± ì‹¤íŒ¨')
                st.markdown(final_response)

                # ë””ë²„ê·¸ ì •ë³´ (Expander)
                with st.expander("ğŸ” ì‹¤í–‰ ì •ë³´ ë³´ê¸°"):
                    st.write("**íŒŒì‹±ëœ ì¿¼ë¦¬:**")
                    st.json(final_state.get('parsed_query', {}))

                    st.write("**ë°ì´í„° ê²€ì¦:**")
                    st.json(final_state.get('data_validation', {}))

                    st.write("**ì„ íƒëœ íˆ´:**")
                    selected_tools = final_state.get('selected_tools', [])
                    st.write(", ".join(selected_tools) if selected_tools else "ì—†ìŒ")

                    st.write("**íˆ´ ì‹¤í–‰ ê²°ê³¼:**")
                    tool_results = final_state.get('tool_results', {})
                    for tool_name, result in tool_results.items():
                        status = result.get('status', 'unknown')
                        st.write(f"- {tool_name}: {status}")

                # ì‘ë‹µ ì €ì¥ (ì¬ì§ˆë¬¸ ì •ë³´ í¬í•¨)
                needs_clarification = final_state.get('needs_clarification', False)
                clarification_type = final_state.get('clarification_type', 'none')

                msg_data = {
                    'role': 'assistant',
                    'content': final_response,
                    'msg_id': len(st.session_state.v5_messages),  # ê³ ìœ  ID
                }

                # ë“œë¡­ë‹¤ìš´ ì¬ì§ˆë¬¸ì¸ ê²½ìš°
                if needs_clarification and clarification_type == 'dropdown':
                    msg_data['show_dropdowns'] = True
                    msg_data['available_channels'] = final_state.get('available_channels', [])
                    msg_data['available_brands'] = final_state.get('available_brands', [])
                    msg_data['available_products'] = final_state.get('available_products', [])
                    msg_data['parsed_query'] = final_state.get('parsed_query', {})

                st.session_state.v5_messages.append(msg_data)

            except Exception as e:
                error_msg = f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}"
                st.error(error_msg)
                import traceback
                with st.expander("ìƒì„¸ ì˜¤ë¥˜ ì •ë³´"):
                    st.code(traceback.format_exc())

                # ì˜¤ë¥˜ë„ íˆìŠ¤í† ë¦¬ì— ì €ì¥
                st.session_state.v5_messages.append({
                    'role': 'assistant',
                    'content': error_msg
                })

#//==============================================================================//#
# ì‹¤í–‰
#//==============================================================================//#

if __name__ == "__main__":
    main()
