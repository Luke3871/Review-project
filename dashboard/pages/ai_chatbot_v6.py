#//==============================================================================//#
"""
ai_chatbot_v6.py
V6 LangGraph Text-to-SQL ì±—ë´‡ í˜ì´ì§€

last_updated : 2025.10.29
"""
#//==============================================================================//#

import streamlit as st
import sys
import os

# ê²½ë¡œ ì„¤ì •
current_dir = os.path.dirname(os.path.abspath(__file__))
dashboard_dir = os.path.dirname(current_dir)
project_root = os.path.dirname(dashboard_dir)

# ai_engines ê²½ë¡œ ì¶”ê°€
ai_engines_dir = os.path.join(dashboard_dir, 'ai_engines')
if ai_engines_dir not in sys.path:
    sys.path.insert(0, ai_engines_dir)

# V6 ëª¨ë“ˆ ì„í¬íŠ¸
from v6_langgraph_agent.graph import create_graph
from v6_langgraph_agent.query_logger import QueryLogger
from v6_langgraph_agent.config import FEEDBACK_REASONS

#//==============================================================================//#
# ë©”ì¸
#//==============================================================================//#

def main():
    st.header("ğŸ¤– AI Chatbot V6")
    st.caption("Text-to-SQL & AI Visual Agent (LangGraph)")

    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if 'v6_messages' not in st.session_state:
        st.session_state.v6_messages = []
    if 'v6_api_key' not in st.session_state:
        st.session_state.v6_api_key = ""
    if 'v6_logger' not in st.session_state:
        username = st.session_state.get('username', 'anonymous')
        st.session_state.v6_logger = QueryLogger(username=username)

    # ì‚¬ì´ë“œë°”
    show_sidebar()

    # API í‚¤ ì…ë ¥ (ë©”ì¸ í™”ë©´ ìƒë‹¨)
    if not st.session_state.v6_api_key:
        st.info("ğŸ‘‹ ì‹œì‘í•˜ë ¤ë©´ ë¨¼ì € OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”")

        col1, col2 = st.columns([3, 1])
        with col1:
            api_key_input = st.text_input(
                "OpenAI API Key",
                type="password",
                placeholder="sk-...",
                help="GPT-4o-minië¥¼ ì‚¬ìš©í•˜ì—¬ SQLì„ ìƒì„±í•©ë‹ˆë‹¤",
                key="api_key_input"
            )
        with col2:
            st.write("")  # ê°„ê²©
            st.write("")  # ê°„ê²©
            if st.button("âœ… ì„¤ì •", use_container_width=True, key="set_api_key"):
                if api_key_input and len(api_key_input) > 20:
                    st.session_state.v6_api_key = api_key_input
                    st.success("API í‚¤ê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤!")
                    st.rerun()
                else:
                    st.error("ì˜¬ë°”ë¥¸ API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”")

        return  # API í‚¤ ì—†ìœ¼ë©´ ì—¬ê¸°ì„œ ë©ˆì¶¤

    # ì±„íŒ… íˆìŠ¤í† ë¦¬ í‘œì‹œ
    for idx, msg in enumerate(st.session_state.v6_messages):
        with st.chat_message(msg['role']):
            st.markdown(msg['content'])

            # ì‹œê°í™”ê°€ ìˆìœ¼ë©´ í‘œì‹œ
            if msg['role'] == 'assistant' and msg.get('visualizations'):
                show_visualizations(msg['visualizations'])

            # í…Œì´ë¸”ì´ ìˆìœ¼ë©´ í‘œì‹œ
            if msg['role'] == 'assistant' and msg.get('tables'):
                show_tables(msg['tables'])

            # ìƒì„±ëœ ì´ë¯¸ì§€ í‘œì‹œ
            if msg['role'] == 'assistant' and msg.get('generated_images'):
                show_generated_images(msg['generated_images'])

            # ë©”íƒ€ë°ì´í„° í‘œì‹œ
            if msg['role'] == 'assistant' and msg.get('metadata'):
                show_metadata(msg['metadata'])

            # Debug ì¶”ì  ì •ë³´ (Debug ëª¨ë“œì¼ ë•Œë§Œ, íˆìŠ¤í† ë¦¬)
            if msg['role'] == 'assistant' and st.session_state.get('v6_debug_mode', False) and msg.get('debug_traces'):
                show_debug_traces(msg['debug_traces'])

            # í”¼ë“œë°± ë²„íŠ¼ (assistant ë©”ì‹œì§€ì—ë§Œ)
            if msg['role'] == 'assistant' and msg.get('log_id'):
                show_feedback_buttons(msg['log_id'], idx)

    # ì‚¬ìš©ì ì…ë ¥
    if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ë¹Œë¦¬í”„ ë³´ìŠµë ¥ ì–´ë•Œ?)"):

        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        st.session_state.v6_messages.append({
            'role': 'user',
            'content': prompt
        })

        with st.chat_message('user'):
            st.markdown(prompt)

        # AI ì‘ë‹µ
        with st.chat_message('assistant'):
            with st.spinner('ë¶„ì„ ì¤‘...'):

                # ì§„í–‰ìƒí™© í‘œì‹œë¥¼ ìœ„í•œ placeholder
                progress_placeholder = st.empty()

                # V6 ì‹¤í–‰
                response = execute_v6_agent(
                    prompt,
                    st.session_state.v6_api_key,
                    progress_placeholder
                )

                # ì§„í–‰ìƒí™© ì§€ìš°ê¸°
                progress_placeholder.empty()

                # ì‘ë‹µ í‘œì‹œ
                response_text = response.get('text', 'ì‘ë‹µì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.')
                st.markdown(response_text)

                # ì‹œê°í™”
                if response.get('visualizations'):
                    show_visualizations(response['visualizations'])

                # ì‹œê°í™” ì œì•ˆ (suggest ì „ëµ)
                if response.get('visualization_suggestions'):
                    show_visualization_suggestions(response['visualization_suggestions'])

                # í…Œì´ë¸”
                if response.get('tables'):
                    show_tables(response['tables'])

                # ìƒì„±ëœ ì´ë¯¸ì§€
                if response.get('generated_images'):
                    show_generated_images(response['generated_images'])

                # ë©”íƒ€ë°ì´í„°
                if response.get('metadata'):
                    show_metadata(response['metadata'])

                # Debug ì¶”ì  ì •ë³´ (Debug ëª¨ë“œì¼ ë•Œë§Œ)
                if st.session_state.get('v6_debug_mode', False) and response.get('debug_traces'):
                    show_debug_traces(response['debug_traces'])

        # ì‘ë‹µ ì €ì¥
        st.session_state.v6_messages.append({
            'role': 'assistant',
            'content': response.get('text', 'ì‘ë‹µì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.'),
            'visualizations': response.get('visualizations'),
            'tables': response.get('tables'),
            'generated_images': response.get('generated_images'),
            'metadata': response.get('metadata'),
            'debug_traces': response.get('debug_traces'),  # Debug ì¶”ì  ì •ë³´
            'log_id': response.get('log_id')
        })

        st.rerun()


def show_sidebar():
    """ì‚¬ì´ë“œë°” UI"""

    with st.sidebar:
        st.markdown("### âš™ï¸ ì„¤ì •")

        # API í‚¤ ìƒíƒœ í‘œì‹œ
        if st.session_state.v6_api_key:
            st.success("âœ… API í‚¤ ì„¤ì •ë¨")
            if st.button("ğŸ”„ API í‚¤ ë³€ê²½", use_container_width=True):
                st.session_state.v6_api_key = ""
                st.rerun()
        else:
            st.info("ë©”ì¸ í™”ë©´ì—ì„œ API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”")

        st.markdown("---")

        # Debug ëª¨ë“œ í† ê¸€ (Phase 2: UI í”¼ë“œë°± ê°œì„ )
        debug_mode = st.checkbox(
            "ğŸ”§ Debug ëª¨ë“œ (ê°œë°œììš©)",
            value=st.session_state.get('v6_debug_mode', False),
            help="LLM í”„ë¡¬í”„íŠ¸ì™€ ì‘ë‹µì„ ì¶”ì í•©ë‹ˆë‹¤"
        )
        st.session_state.v6_debug_mode = debug_mode

        if debug_mode:
            st.info("ğŸ’¡ Debug ëª¨ë“œ í™œì„±í™”: ë‹µë³€ í•˜ë‹¨ì— LLM ì¶”ì  ì •ë³´ê°€ í‘œì‹œë©ë‹ˆë‹¤")

        st.markdown("---")

        # ëŒ€í™” ì´ˆê¸°í™” ë²„íŠ¼
        if st.button("ğŸ—‘ï¸ ëŒ€í™” ì´ˆê¸°í™”", use_container_width=True):
            st.session_state.v6_messages = []
            st.rerun()

        st.markdown("---")

        # ì‚¬ìš© í†µê³„
        st.markdown("### ğŸ“Š ì‚¬ìš© í†µê³„")

        logger = st.session_state.v6_logger
        stats = logger.get_statistics()

        if stats.get('total_queries', 0) > 0:
            col1, col2 = st.columns(2)
            with col1:
                st.metric("ì´ ì§ˆë¬¸", f"{stats['total_queries']}ê°œ")
            with col2:
                st.metric("í‰ê·  ì‹œê°„", f"{stats['avg_duration']}ì´ˆ")

            # í”¼ë“œë°± í†µê³„
            feedback_stats = logger.get_feedback_statistics()
            if feedback_stats.get('satisfaction_rate', 0) > 0:
                st.metric(
                    "ë§Œì¡±ë„",
                    f"{feedback_stats['satisfaction_rate']}%",
                    delta=f"{feedback_stats['positive_count']}ğŸ‘ {feedback_stats['negative_count']}ğŸ‘"
                )
        else:
            st.info("ì•„ì§ ì§ˆë¬¸ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤")

        st.markdown("---")

        # ì˜ˆì‹œ ì§ˆë¬¸
        st.markdown("### ğŸ’¡ ì˜ˆì‹œ ì§ˆë¬¸")

        example_queries = [
            "ë¹Œë¦¬í”„ ë³´ìŠµë ¥ ì–´ë•Œ?",
            "VTë‘ í† ë¦¬ë“  ë¹„êµí•´ì¤˜",
            "ì˜¬ë¦¬ë¸Œì˜ í‰ì  ë†’ì€ ì œí’ˆì€?",
            "ìµœê·¼ 3ê°œì›” ì¸ê¸° ì œí’ˆ ë³´ì—¬ì¤˜",
            "ë³µí•©ì„± í”¼ë¶€ ì¶”ì²œ ì œí’ˆ"
        ]

        for query in example_queries:
            if st.button(f"ğŸ’¬ {query}", key=f"example_{query}", use_container_width=True):
                # ì§ì ‘ ì…ë ¥ì°½ì— ë„£ê¸°
                st.session_state.example_query = query
                st.rerun()


def execute_v6_agent(user_query: str, api_key: str, progress_placeholder) -> dict:
    """V6 Agent ì‹¤í–‰"""

    try:
        # í™˜ê²½ë³€ìˆ˜ì— API í‚¤ ì„¤ì • (OpenAI í´ë¼ì´ì–¸íŠ¸ê°€ ìë™ìœ¼ë¡œ ì½ìŒ)
        import os
        os.environ["OPENAI_API_KEY"] = api_key

        # LangGraph ìƒì„±
        graph = create_graph()

        # ì§„í–‰ìƒí™© ì½œë°±
        def update_progress(progress_text):
            progress_placeholder.markdown(progress_text)

        # ëŒ€í™” íˆìŠ¤í† ë¦¬ êµ¬ì„± (ìµœê·¼ 10ê°œ ë©”ì‹œì§€ = 5í„´)
        conversation_history = []
        if 'v6_messages' in st.session_state:
            # ë§ˆì§€ë§‰ 10ê°œ ë©”ì‹œì§€ë§Œ ì‚¬ìš© (user + assistant ìŒ 5ê°œ)
            recent_messages = st.session_state.v6_messages[-10:]
            for msg in recent_messages:
                conversation_history.append({
                    "role": msg["role"],
                    "content": msg["content"]
                })

        # ì´ˆê¸° ìƒíƒœ
        initial_state = {
            "user_query": user_query,
            "ui_callback": update_progress,
            "debug_mode": st.session_state.get('v6_debug_mode', False),  # Debug ëª¨ë“œ ì „ë‹¬
            "conversation_history": conversation_history,  # ëŒ€í™” íˆìŠ¤í† ë¦¬ ì „ë‹¬
            "messages": [],
            "error": None
        }

        # ë””ë²„ê¹…: Graph ì‹¤í–‰ ì‹œì‘
        print(f"\n[DEBUG] ===== Graph ì‹¤í–‰ ì‹œì‘ =====")
        print(f"[DEBUG] Graph - user_query: {user_query}")
        print(f"[DEBUG] Graph - conversation_history: {len(conversation_history)}ê°œ ë©”ì‹œì§€")

        # ì‹¤í–‰
        final_state = graph.invoke(initial_state)

        # ë””ë²„ê¹…: Graph ì‹¤í–‰ ì™„ë£Œ
        print(f"[DEBUG] ===== Graph ì‹¤í–‰ ì™„ë£Œ =====")
        print(f"[DEBUG] Graph - final_state keys: {list(final_state.keys())}")
        print(f"[DEBUG] Graph - error: {final_state.get('error')}")
        print(f"[DEBUG] Graph - final_response ì¡´ì¬: {'final_response' in final_state}")
        if 'final_response' in final_state:
            fr = final_state['final_response']
            print(f"[DEBUG] Graph - final_response type: {type(fr)}")
            if isinstance(fr, dict):
                print(f"[DEBUG] Graph - final_response keys: {list(fr.keys())}")

        # ìµœì¢… ì‘ë‹µ
        final_response = final_state.get("final_response", {})

        # ë¡œê·¸ ì €ì¥
        logger = st.session_state.v6_logger
        logger.log_query(
            user_query=user_query,
            state=final_state,
            final_response=final_response,
            error=final_state.get("error")
        )

        # ìµœê·¼ ë¡œê·¸ ID ê°€ì ¸ì˜¤ê¸° (í”¼ë“œë°±ìš©)
        history = logger.get_user_history(limit=1)
        log_id = history[0]['log_id'] if history else None

        # ì‘ë‹µì— log_id ì¶”ê°€
        final_response['log_id'] = log_id

        # Debug ëª¨ë“œ ì¶”ì  ì •ë³´ ì¶”ê°€
        if st.session_state.get('v6_debug_mode', False):
            final_response['debug_traces'] = final_state.get('debug_traces', [])

        return final_response

    except Exception as e:
        # ì˜ˆì™¸ ë°œìƒ ì‹œì—ë„ ë¡œê·¸ ì €ì¥
        logger = st.session_state.v6_logger
        error_info = {"exception": str(e), "type": type(e).__name__}

        logger.log_query(
            user_query=user_query,
            state={"error": error_info, "messages": []},
            final_response={"text": f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}"},
            error=error_info
        )

        error_response = {
            "text": f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
            "visualizations": None,
            "tables": None,
            "metadata": {"error": str(e)},
            "log_id": None
        }
        return error_response


def show_visualizations(visualizations: list):
    """ì‹œê°í™” í‘œì‹œ"""

    if not visualizations:
        return

    st.markdown("---")
    st.markdown("#### ğŸ“ˆ ì‹œê°í™”")

    for viz in visualizations:
        viz_type = viz.get('type')
        figure = viz.get('figure')

        if figure:
            if viz_type == 'wordcloud':
                # Matplotlib figure
                st.pyplot(figure, use_container_width=False)
            else:
                # Plotly figure
                st.plotly_chart(figure, use_container_width=False)


def show_tables(tables: dict):
    """í…Œì´ë¸” í‘œì‹œ"""

    if not tables:
        return

    st.markdown("---")
    st.markdown("#### ğŸ“‹ ë°ì´í„°")

    for table_name, table_data in tables.items():
        if table_data:
            st.markdown(f"**{table_name}**")

            import pandas as pd
            df = pd.DataFrame(table_data['data'], columns=table_data['columns'])
            st.dataframe(df, use_container_width=True, hide_index=True)


def show_visualization_suggestions(suggestions: list):
    """ì‹œê°í™” ì œì•ˆ í‘œì‹œ"""

    if not suggestions:
        return

    st.markdown("---")
    st.markdown("#### ğŸ’¡ ì‹œê°í™” ì œì•ˆ")
    st.info("ë‹¤ìŒ ì‹œê°í™” ì˜µì…˜ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:")

    # ì œì•ˆ íƒ€ì…ë³„ ì•ˆë‚´ ë©”ì‹œì§€
    viz_labels = {
        "line_chart": "ğŸ“ˆ ë¼ì¸ ì°¨íŠ¸ (ì‹œê³„ì—´ íŠ¸ë Œë“œ)",
        "bar_chart": "ğŸ“Š ë§‰ëŒ€ ì°¨íŠ¸ (ë¹„êµ ë¶„ì„)",
        "wordcloud": "â˜ï¸ ì›Œë“œí´ë¼ìš°ë“œ (í‚¤ì›Œë“œ ë¶„ì„)"
    }

    cols = st.columns(len(suggestions))
    for i, viz_type in enumerate(suggestions):
        with cols[i]:
            label = viz_labels.get(viz_type, viz_type)
            st.button(
                label,
                key=f"viz_suggest_{viz_type}",
                use_container_width=True,
                disabled=True  # ì¼ë‹¨ ë¹„í™œì„±í™” (ë‚˜ì¤‘ì— í´ë¦­ ì‹œ ì‹œê°í™” ìƒì„± ê¸°ëŠ¥ ì¶”ê°€)
            )

    st.caption("ğŸ’¬ ì‹œê°í™”ê°€ í•„ìš”í•˜ì‹œë©´ 'ì›Œë“œí´ë¼ìš°ë“œ ë³´ì—¬ì¤˜' ê°™ì´ ëª…ì‹œì ìœ¼ë¡œ ìš”ì²­í•´ì£¼ì„¸ìš”!")


def show_metadata(metadata: dict):
    """ë©”íƒ€ë°ì´í„° í‘œì‹œ"""

    if not metadata:
        return

    with st.expander("â„¹ï¸ ì‹¤í–‰ ì •ë³´"):
        col1, col2, col3 = st.columns(3)

        with col1:
            st.metric("ì²˜ë¦¬ ì‹œê°„", f"{metadata.get('total_duration', 0):.2f}ì´ˆ")
        with col2:
            st.metric("ë³µì¡ë„", metadata.get('complexity', 'unknown'))
        with col3:
            st.metric("SQL ì¿¼ë¦¬", f"{metadata.get('total_queries', 0)}ê°œ")

        # ì¶”ê°€ ì •ë³´
        if metadata.get('total_data_rows'):
            st.write(f"ğŸ“Š ë¶„ì„ ë°ì´í„°: {metadata['total_data_rows']:,}ê°œ ë¦¬ë·°")

        if metadata.get('visualization_confidence'):
            st.write(f"ğŸ¨ ì‹œê°í™” ì‹ ë¢°ë„: {metadata['visualization_confidence']:.0%}")

        # SQL ì¿¼ë¦¬ í‘œì‹œ (ìƒˆë¡œ ì¶”ê°€)
        sql_queries = metadata.get('sql_queries', [])
        if sql_queries:
            st.markdown("---")
            st.markdown("### ğŸ“‹ ìƒì„±ëœ SQL ì¿¼ë¦¬")

            for i, sql_meta in enumerate(sql_queries, 1):
                purpose = sql_meta.get('purpose', f'Query {i}')
                with st.expander(f"Q{i}: {purpose}", expanded=False):
                    st.code(sql_meta.get('sql', ''), language='sql')

                    # ë¶€ê°€ ì •ë³´
                    col_a, col_b = st.columns(2)
                    with col_a:
                        st.caption(f"ğŸ’¡ {sql_meta.get('explanation', '')}")
                    with col_b:
                        st.caption(f"ğŸ“Š ì˜ˆìƒ ê²°ê³¼: {sql_meta.get('estimated_rows', 0)}ê±´")


def show_feedback_buttons(log_id: int, message_idx: int):
    """í”¼ë“œë°± ë²„íŠ¼"""

    # ì´ë¯¸ í”¼ë“œë°±ì„ ë‚¨ê¸´ ê²½ìš° ì²´í¬
    feedback_key = f"feedback_{log_id}"
    if feedback_key in st.session_state:
        st.success(f"âœ… í”¼ë“œë°± ì™„ë£Œ: {st.session_state[feedback_key]}")
        return

    st.markdown("---")
    st.markdown("**ì´ ë‹µë³€ì´ ë„ì›€ì´ ë˜ì—ˆë‚˜ìš”?**")

    col1, col2 = st.columns(2)

    with col1:
        if st.button("ğŸ‘ ì¢‹ì•„ìš”", key=f"pos_{log_id}_{message_idx}", use_container_width=True):
            show_feedback_dialog(log_id, "positive")

    with col2:
        if st.button("ğŸ‘ ë³„ë¡œì˜ˆìš”", key=f"neg_{log_id}_{message_idx}", use_container_width=True):
            show_feedback_dialog(log_id, "negative")


def show_feedback_dialog(log_id: int, feedback_type: str):
    """í”¼ë“œë°± ìƒì„¸ ì…ë ¥"""

    # ëª¨ë‹¬ ëŒ€ì‹  expander ì‚¬ìš©
    with st.expander("ğŸ“ í”¼ë“œë°± ì‘ì„±", expanded=True):

        # ì´ìœ  ì„ íƒ
        reasons = FEEDBACK_REASONS[feedback_type]
        selected_reason = st.selectbox(
            "ì´ìœ ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”",
            reasons,
            key=f"reason_{log_id}"
        )

        # ì¶”ê°€ ì½”ë©˜íŠ¸
        comment = st.text_area(
            "ì¶”ê°€ ì˜ê²¬ (ì„ íƒ)",
            placeholder="ê°œì„ ì´ í•„ìš”í•œ ë¶€ë¶„ì´ë‚˜ ì¢‹ì•˜ë˜ ì ì„ ì•Œë ¤ì£¼ì„¸ìš”",
            key=f"comment_{log_id}"
        )

        # ì œì¶œ ë²„íŠ¼
        if st.button("ì œì¶œ", key=f"submit_{log_id}"):
            logger = st.session_state.v6_logger
            success = logger.save_feedback(
                log_id=log_id,
                feedback=feedback_type,
                reason=selected_reason,
                comment=comment if comment else None
            )

            if success:
                st.session_state[f"feedback_{log_id}"] = "ğŸ‘ ì¢‹ì•„ìš”" if feedback_type == "positive" else "ğŸ‘ ë³„ë¡œì˜ˆìš”"
                st.success("í”¼ë“œë°±ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤!")
                st.rerun()
            else:
                st.error("í”¼ë“œë°± ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")


def show_generated_images(generated_images: list):
    """ìƒì„±ëœ ì´ë¯¸ì§€ í‘œì‹œ (AI Visual Agent)"""

    if not generated_images:
        return

    st.markdown("---")
    st.markdown("#### ğŸ¨ ìƒì„±ëœ ë””ìì¸ ì‹œì•ˆ")

    for idx, img_data in enumerate(generated_images):
        local_path = img_data.get('local_path')
        revised_prompt = img_data.get('revised_prompt')
        timestamp = img_data.get('timestamp', '')

        # ì´ë¯¸ì§€ í‘œì‹œ
        if local_path and os.path.exists(local_path):
            st.image(local_path, caption=f"Daiso ì±„ë„ ìµœì í™” ë””ìì¸ #{idx+1}", width=700)

            # ìƒì„¸ ì •ë³´ (expander)
            with st.expander(f"ğŸ“ ë””ìì¸ #{idx+1} ìƒì„¸ ì •ë³´"):
                st.markdown(f"**ìƒì„± ì‹œê°„:** {timestamp}")
                st.markdown(f"**íŒŒì¼ ê²½ë¡œ:** `{local_path}`")

                if revised_prompt:
                    st.markdown("**Gemini Prompt:**")
                    st.code(revised_prompt, language="text")
        else:
            st.warning(f"ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {local_path}")


def show_debug_traces(debug_traces: list):
    """Debug ì¶”ì  ì •ë³´ í‘œì‹œ (ê°œë°œììš©)"""

    if not debug_traces:
        return

    with st.expander("ğŸ”§ Debug ì¶”ì  ì •ë³´ (ê°œë°œììš©)", expanded=False):
        st.caption("LLM í”„ë¡¬í”„íŠ¸ì™€ ì‘ë‹µì„ ì¶”ì í•©ë‹ˆë‹¤")

        for i, trace in enumerate(debug_traces, 1):
            node = trace.get('node', 'Unknown')
            step = trace.get('step', 'Unknown')

            st.markdown(f"### Trace {i}: {node} - {step}")

            # í”„ë¡¬í”„íŠ¸ í‘œì‹œ
            if trace.get('prompt'):
                with st.expander("ğŸ“ LLM í”„ë¡¬í”„íŠ¸", expanded=False):
                    prompt_text = trace['prompt']
                    # ë„ˆë¬´ ê¸¸ë©´ ì˜ë¼ë‚´ê¸°
                    if len(prompt_text) > 2000:
                        st.text(prompt_text[:2000] + "\n\n... (truncated)")
                    else:
                        st.text(prompt_text)

            # LLM ì‘ë‹µ í‘œì‹œ
            if trace.get('llm_response'):
                with st.expander("ğŸ’¬ LLM ì›ë³¸ ì‘ë‹µ", expanded=False):
                    response_text = trace['llm_response']
                    # ë„ˆë¬´ ê¸¸ë©´ ì˜ë¼ë‚´ê¸°
                    if len(response_text) > 2000:
                        st.text(response_text[:2000] + "\n\n... (truncated)")
                    else:
                        st.text(response_text)

            # íŒŒì‹±ëœ ê²°ê³¼ (ìˆìœ¼ë©´)
            if trace.get('parsed_result'):
                with st.expander("âœ… íŒŒì‹±ëœ ê²°ê³¼", expanded=False):
                    st.json(trace['parsed_result'])

            st.markdown("---")


if __name__ == "__main__":
    main()
